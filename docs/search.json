[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Evaluation d’impact de politiques et projets",
    "section": "",
    "text": "Preface",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#démarche",
    "href": "index.html#démarche",
    "title": "Evaluation d’impact de politiques et projets",
    "section": "Démarche",
    "text": "Démarche\nCe contenu est un support de formation conçu pour initier à l’économétrie spatiale chercheurs, doctorants et étudiants s’orientant vers une thèse. Le cas d’étude choisi pour servir de fil rouge à ces travaux est l’impact des aires protégées sur la déforestation, mais les méthodes décrites sont appropriées pour évaluer de nombreux types d’intervention ayant une dimension spatiale, que ce soit en matière d’environnement, d’agriculture, de gestion des risques ou de développement urbain. Le document a été élaboré avec les priorités suivantes :\n\nCompréhension des enjeux théoriques et méthodologiques soulevés par les évaluations d’impact ;\nIdentification des spécificités et opportunités liées à l’évaluation d’interventions spatialisées ;\nObtention de données spatiale permettant de démontrer et de quantifier l’impact ;\nCompréhension des différentes approches pour constituer un contrefactuel : randomisation, appariement, comparaison avant-après, différence de différences ;\nFamiliarisation avec l’outil de traitement statistique R;\nDéveloppement d’un regard critique sur la pertinence et la fiabilité des données mobilisées.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#tany-vao-et-betsaka",
    "href": "index.html#tany-vao-et-betsaka",
    "title": "Evaluation d’impact de politiques et projets",
    "section": "Tany Vao et BETSAKA",
    "text": "Tany Vao et BETSAKA\nCe contenu a été initialement développé afin de servir de support pédagogique pour l’atelier “évaluation des politiques” de la session 2022 des Universités en sciences sociales Tany Vao. Les universités Tany Vao visent à dispenser une formation à la recherche de haut niveau à l’attention de doctorants et jeunes chercheurs de Madagascar et d’Afrique de l’Ouest. Cet atelier a été réitéré à l’Université d’Antananarivo en 2023 et 2024 dans le cadre du projet BETSAKA. Le projet BETSAKA vise à évaluer l’impact environnemental et socioéconomique des politiques de conservation à Madagascar, en priorisant le renforcement des capacités locales de rercherche et le dialogue chercheurs-décideurs-opérationnels.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#contributions",
    "href": "index.html#contributions",
    "title": "Evaluation d’impact de politiques et projets",
    "section": "Contributions",
    "text": "Contributions\nCet ouvrage a bénéficié de nombreuses contributions :\n\nPour la première édition : Marc Bouvier, Kenneth Houngbedji, Jeanne de Montalembert et Marin Ferry ;\nPour la seconde édition : Lenaïg Moign et Clément Sambandahy ;\nPour la troisième édition : Ingrid Dallmann et Melvin Wong.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "00_programme.html",
    "href": "00_programme.html",
    "title": "Programme",
    "section": "",
    "text": "JOUR 1 : L’évaluation d’impact : Pourquoi ? Comment ?",
    "crumbs": [
      "Programme"
    ]
  },
  {
    "objectID": "00_programme.html#jour-1-lévaluation-dimpact-pourquoi-comment",
    "href": "00_programme.html#jour-1-lévaluation-dimpact-pourquoi-comment",
    "title": "Programme",
    "section": "",
    "text": "8h - 9h30 : Présentation de l’atelier (60 minutes)\n\nObjectif, contenu, programme, supports\nMéthode, exercices et constitution des groupes\nFormateurs et stagiaires (expérience R…)\n\nDiscussion/questions (30 minutes)\n\nLien entre la formation et les agendas des participants\nIntérêt de la dimension spatiale\nFil rouge pour expliquer les méthodes d’analyses : l’impact des aires protégées sur la déforestation\n\n\n9h30 - 10h : Pause\n10h - 12h : Définition des objectifs de l’évaluation (90 minutes)\n\nSuivi, évaluations classiques et d’impact : liens et différences\nCorrélation vs causalité : théorie des évaluations d’impact\n\nDiscussion/questions (30 minutes)\n\nIllustrations autour de cas concrets\n\n12h - 13h30 : Pause déjeuner\n13h30 - 14h45 : Tour d’horizon des méthodes d’évaluation (45 minutes)\n\nMéthodes par assignation aléatoire\nBACI (Before-after-control-impact)\nAppariement, double différence, contrôles synthétiques\nRégression sur discontinuité et variables instrumentales\nCas d’application et avantages-inconvénients de chacune\nDurée :\n\nDiscussion/questions (30 minutes)\n\nFocus sur les méthodes qui ne seront pas approfondies\nDurée :\n\n14h45 - 15h : Pause\n15h30 - 17h : Étude d’articles : cadrage (30 minutes)\nDiscussion/questions (60 minutes)\n\nFormation des groupes\nIdentification des articles\nDébut des travaux pratiques (pas finis en séance)\nDébrieffing pour s’assurer que la méthode est bien comprise",
    "crumbs": [
      "Programme"
    ]
  },
  {
    "objectID": "00_programme.html#jour-2-initiation-à-r",
    "href": "00_programme.html#jour-2-initiation-à-r",
    "title": "Programme",
    "section": "JOUR 2 : Initiation à R",
    "text": "JOUR 2 : Initiation à R\n\n8h - 8h30 : Environnement technique (30 minutes)\n8h30 - 9h : Interface et formats (60 minutes)\n9h30 - 10h : Pause\n10h - 12h : Règles de code, assignation, objets (120 minutes)\n12h - 13h30 : Pause déjeuner\n13h30 - 15h : Fonctions, librairies, aide (90 minutes)\n15h - 15h30 : Pause\n15h30 - 17h : Import de données, valeurs manquantes (90 minutes)",
    "crumbs": [
      "Programme"
    ]
  },
  {
    "objectID": "00_programme.html#jour-3-initiation-à-r-et-restitution-des-lectures-darticles",
    "href": "00_programme.html#jour-3-initiation-à-r-et-restitution-des-lectures-darticles",
    "title": "Programme",
    "section": "JOUR 3 : Initiation à R et restitution des lectures d’articles",
    "text": "JOUR 3 : Initiation à R et restitution des lectures d’articles\n\n8h - 9h30 : Manipulations de données avec tidyverse (90 minutes)\n\nOpérateur “pipe” pour chaîner les opérations\nOpérations essentielles : sélectionner, filtrer…\n\n9h30 - 10h : Pause\n10h - 12h : Manipulations de données avec tidyverse (120 minutes)\n\nSuite des opérations essentielles\nJointures\n\n12h - 13h30 : Pause déjeuner\n13h30 - 15h : Tables (gt) et graphiques (ggplot2) (90 minutes)\n15h - 15h30 : Pause\n15h30 - 17h : Restitution des lectures d’articles (90 minutes)",
    "crumbs": [
      "Programme"
    ]
  },
  {
    "objectID": "00_programme.html#jour-4-données-spatiales-et-mapme.biodiversity",
    "href": "00_programme.html#jour-4-données-spatiales-et-mapme.biodiversity",
    "title": "Programme",
    "section": "JOUR 4 : Données spatiales et mapme.biodiversity",
    "text": "JOUR 4 : Données spatiales et mapme.biodiversity\n\n8h - 8h30 : Présentation des données spatiales (30 minutes)\n\nTypologies, sources et principes techniques\n\nQuestions / discussion (15 minutes)\n\nAvantages et inconvénients de ces sources\nExpériences des participants dans leur utilisation\nOpportunités pour leurs sujets de recherche\n\n8h30 - 9h15 : Manipulation de données spatiales d’AP sur R (45 minutes)\n\nTypes : vecteur, raster\nAnalogie avec les données tabulaires\nOpérations spécifiquement spatiales\n\n9h15 - 9h30 : Pause\n9h30 - 10h15 : Visualisation et analyse des données spatiales (45 minutes)\n\nPoint avec tmap\nClarification sur les projections\nPoursuite des exercices pratiques sur les aires protégées : comparaison des sources, statistiques descriptives\n\n12h - 13h30 : Pause déjeuner\n13h30 - 15h : Présentation du package mapme.biodiversity, discussion/questions et manipulation (90 minutes)\n\nConsultation des ressources disponibles\nDécouverte des données\nPréparation des données pour les aires protégées\n\n15h - 15h30 : Pause\n15h30 - 17h : Poursuite des analyses (90 minutes)\n\nCréation d’une grille sur le territoire\nExemple bref d’acquisition des données et calcul sur la grille",
    "crumbs": [
      "Programme"
    ]
  },
  {
    "objectID": "00_programme.html#jour-5-méthodes-expérimentales-et-observationnelles-avantaprès",
    "href": "00_programme.html#jour-5-méthodes-expérimentales-et-observationnelles-avantaprès",
    "title": "Programme",
    "section": "JOUR 5 : Méthodes expérimentales et observationnelles avant/après",
    "text": "JOUR 5 : Méthodes expérimentales et observationnelles avant/après\n\n8h - 9h30 : Randomisation (45 minutes)\nQuestions / discussion (45 minutes)\n\nDébat autour de la pertinence des RCT\nDéfis méthodologiques et pratique de la faisabilité\nQuestions éthiques\n\n9h30 - 10h : Pause\n10h - 12h : Application pratique : faisons “comme si” les AP étaient créées aléatoirement (2 heures)\n\nAnalyse de données\nInterprétations\nTests d’équilibre\n\n12h - 13h30 : Pause déjeuner\n13h30 - 15h : Avant/Après (90 minutes)\nDiscussion/questions et manipulation\n\nLimites de l’approche\nMoyens de vérification des tendances\n\n15h - 15h30 : Pause\n15h30 - 17h : Tests de comparaison et d’équilibre avant-après et avec-sans (90 minutes)",
    "crumbs": [
      "Programme"
    ]
  },
  {
    "objectID": "00_programme.html#jour-6-méthodes-observationnelles-dappariement-matching",
    "href": "00_programme.html#jour-6-méthodes-observationnelles-dappariement-matching",
    "title": "Programme",
    "section": "JOUR 6 : Méthodes observationnelles d’appariement (matching)",
    "text": "JOUR 6 : Méthodes observationnelles d’appariement (matching)\n\n8h - 9h30 : Différentes unités/échelles d’analyse (AP, cellules, pixels…) (30 minutes)\nQuestions / discussion / mise en pratique (90 minutes)\n9h30 - 10h : Pause\n10h - 12h : Appariement (Matching) (90 minutes)\nQuestions / discussion (30 minutes)\n\nClarification du principe d’appariement\nVariables pertinentes pour les aires protégées\nQuestions sur les biais potentiels liés aux variables non observables\n\n12h - 13h30 : Pause déjeuner\n13h30 - 15h : Présentation du package MatchIt (30 minutes)\n\nExercices d’application aux aires protégées (60 minutes)\nSpécification des variables\nAlgorithmes d’appariement\nParamètres associés\n\n15h - 15h30 : Pause\n15h30 - 17h : Suite des exercices d’application aux aires protégées (90 minutes)\n\nTests d’équilibre",
    "crumbs": [
      "Programme"
    ]
  },
  {
    "objectID": "00_programme.html#jour-7-double-différence-et-conclusion",
    "href": "00_programme.html#jour-7-double-différence-et-conclusion",
    "title": "Programme",
    "section": "JOUR 7 : Double différence et conclusion",
    "text": "JOUR 7 : Double différence et conclusion\n\n8h - 9h30 : Double différence (DiD) (60 minutes)\nQuestions / discussion (30 minutes)\n\nIntérêt de l’approche DiD\nEnjeux de validité si plusieurs périodes de comparaison\nStratégies de simplification\n\n9h30 - 10h : Pause\n10h - 12h : Package did (30 minutes)\n\nMise en application (90 minutes)\nUtilisation sur 2 périodes\nUtilisation sur N périodes\nVérification des tendances de prétraitement\n\n12h - 13h30 : Pause déjeuner\n13h30 - 15h : Synthèse et outils pratiques (90 minutes)\n15h - 15h30 : Pause\n15h30 - 17h : Évaluation de la formation et remise des certificats (90 minutes)",
    "crumbs": [
      "Programme"
    ]
  },
  {
    "objectID": "01_introduction.html",
    "href": "01_introduction.html",
    "title": "1  Introduction",
    "section": "",
    "text": "1.1 Cadrage général pour les méthodes d’évaluation\nCliquer ici pour télécharger la présentation\nMentionner également les enjeux de prise en compte du qualitatif.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "01_introduction.html#revue-des-articles",
    "href": "01_introduction.html#revue-des-articles",
    "title": "1  Introduction",
    "section": "1.2 Revue des articles",
    "text": "1.2 Revue des articles\nOn va revoir deux articles récents qui emploient des méthodes semblables à celles que nous allons étudier pendant le cours :\n\nL’article “On track to achieve no net loss of forest at Madagascar’s biggest mine” de Devenish et al. (2022) paru dans Nature Sustainability.\nL’article “Forest loss report card for the world’s protected areas”, de Wolf et al. (2021), paru dans Nature Ecology & Evolution.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "02_bases_R.html",
    "href": "02_bases_R.html",
    "title": "2  Fondamentaux pour l’utilisation de R",
    "section": "",
    "text": "2.1 L’environnement",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Fondamentaux pour l'utilisation de R</span>"
    ]
  },
  {
    "objectID": "02_bases_R.html#lenvironnement",
    "href": "02_bases_R.html#lenvironnement",
    "title": "2  Fondamentaux pour l’utilisation de R",
    "section": "",
    "text": "2.1.1 Différences R et Rstudio\nR est un langage de programmation open source spécialisé dans la statistique et l’analyse des données. Il a été créé pour fournir un environnement convivial pour la manipulation, l’analyse et la visualisation des données.Il existe d’autres langages de programmation comme Python, JavaScript, Java, C++, etc.\nR est utilisé pour effectuer des opérations statistiques, faire de la modélisation, créer des graphiques et effectuer des analyses de données complexes.\nR est extrêmement flexible et extensible grâce à des packages R, qui ajoutent des fonctionnalités supplémentaires.\nRStudio est un environnement de développement intégré (IDE) conçu spécifiquement pour travailler avec le langage R. C’est un logiciel qui fournit une interface utilisateur plus conviviale pour écrire, exécuter et gérer des scripts R. Il existe d’autres IDE, comme Visual Studio Code ou Jupyter Notebook.\nRStudio inclut un éditeur de texte avec coloration syntaxique, un gestionnaire de packages, des fenêtres pour l’affichage des graphiques et des données, et bien d’autres fonctionnalités pour améliorer la productivité des utilisateurs R.\nEn somme, R est le langage de programmation sous-jacent pour l’analyse des données, tandis que RStudio est un environnement de développement qui facilite l’utilisation de R.\n\n\n2.1.2 Sources d’apprentissage\nIl existe de plusieurs ressources en français pour apprendre à coder sur R. Nous vous recommandons en particulier :\n\nIntroduction à R et au Tidyverse (Barnier 2022) Guide-R: Guide pour l’analyse de données d’enquêtes avec R (Larmarange 2024)\nutilitR: documentation collaborative sur R de l’INSEE (Galiana and Meslin 2022)\n\nLes bonnes ressources anglophones gratuites sont très nombreuses et faciles à trouver sur Internet. Le grand classique est R for data science, de Grolemund et Wickham (2022). On se focalise ici avec deux autres qui sont le plus en lien avec nos sujets :\n\nGeocomputation with R, a book on geographic data analysis,visualization and modeling (Lovelace, Nowosad, and Muenchow 2022).\nMapme.biodiversity: Efficient Monitoring of Global Biodiversity Portfolios (Görgen and Bhandari 2022)\n\nN’hésitez pas à chercher directement sur le Web en cas de problème. Vous serez souvent conduits vers les forums stackoverflow ou RStudio, qui sont aussi des ressources très précieuses pour résoudre des problèmes très spécifiques.\nPour un apprentissage interactif, vous pouvez également utiliser ChatGPT. Cet outil basé sur l’intelligence artificielle s’avère particulièrement utile pour les débutants qui ont besoin de support personnalisé ou pour les utilisateurs avancés comme assistant de programmation pour structurer des chaînes de traitement ou aider avec les problèmes les plus courants. Attention toutefois car il arrive régulièrement à ChatGPT “d’halluciner” des réponses lorsqu’il s’agit de questions très spécifiques.\nPour vous retrouver parmi la multitude de packages existants, il existe une ressource précieuse en ligne : CRAN Task View (https://cran.r-project.org/web/views/). Ce registre fournit des recommandations sur les packages présents sur CRAN adaptés à un sujet spécifique.\nIl existe également de superbes cheat-sheet (“antisèches”) qui récapitulent les principales ressource :\n\nhttps://iqss.github.io/dss-workshops/R/Rintro/base-r-cheat-sheet.pdf\nhttps://rstudio.github.io/cheatsheets/\n\n\n\n2.1.3 Interface Rstudio\n\nA : fenêtre script/source B : console C : environnement D : explorateur\nLa fenêtre de script permet d’éditer les fichiers scripts en vue d’éxécuter le code.\nLa console est la fênetre où s’éxécute le code et où on peut directement taper des commandes. Il n’est pas obligatoire de passer par la fenêtre de script.\nLe signe “&gt;” dans votre console est appelé “invite de commande” ou “prompt”. C’est le symbole que la console utilise pour indiquer qu’elle est prête à recevoir des commandes ou des instructions de l’utilisateur. Une fois que vous voyez cet invite, vous pouvez commencer à entrer des commandes en utilisant le langage R. Après avoir entré une commande, vous appuyez sur Entrée pour l’exécuter.\nL’environnement rassemble des fonctionnalités pour suivre le fonctionnement de R, en faisant notamment apparaître les différents objets générés par notre script.\nL’explorateur permet de connaître les fichiers de notre ordinateur, de visualiser les rendus graphiques et cartographiqus, les différentes librairies et l’aide pour l’utilisation de ces dernières.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Fondamentaux pour l'utilisation de R</span>"
    ]
  },
  {
    "objectID": "02_bases_R.html#introduction-au-langage-r",
    "href": "02_bases_R.html#introduction-au-langage-r",
    "title": "2  Fondamentaux pour l’utilisation de R",
    "section": "2.2 Introduction au langage R",
    "text": "2.2 Introduction au langage R\nR est un langage de programmation puissant et flexible, particulièrement adapté pour l’analyse de données et la statistique. Cette section couvre les bases du langage R, en fournissant une introduction aux concepts fondamentaux tels que les objets, les types de données, les fonctions, et les bonnes pratiques de codage. Ce guide est conçu pour vous aider à acquérir les bases nécessaires pour écrire du code efficace et lisible.\n\n2.2.1 La lisibilité du code\nLa lisibilité du code est cruciale pour comprendre ce qu’un script fait, surtout après une certaine période ou lorsqu’on travaille en équipe.\n\nEspaces autour des opérateurs : Utilisez des espaces autour des opérateurs pour améliorer la lisibilité.\n\n\n# Mauvaise lisibilité\ntotal&lt;-10+2\n\n# Bonne lisibilité\ntotal &lt;- 10 + 2\n\n\nCommentaires clairs : En R, un commentaire commence par le symbole #. Tout ce qui est écrit après # sur la même ligne ne sera pas exécuté. Utilisez des commentaires pour expliquer des parties de code complexes ou des étapes importantes.\n\n\n# Calcul du total des deux valeurs\ntotal &lt;- 10 + 2  # Ajout de 10 et 2\n\n\nUtilisation des parenthèses : Pour les expressions complexes, utilisez des parenthèses afin de rendre l’ordre des opérations explicite.\n\n\n# Utilisation des parenthèses pour clarifier l'ordre des opérations\nresultat &lt;- (10 + 2) * (5 / 14) - (2 * 2)\n\n\n2.2.1.1 Exercice\n\nAméliorer la lisibilité : Reprenez le code suivant et améliorez sa lisibilité en ajoutant des espaces et des commentaires appropriés.\n\n\nresultat&lt;-5*(3+2)-1\n\n\n\n\n2.2.2 L’assignation (création d’objets)\nEn R, on utilise &lt;- pour assigner une valeur à un objet. Cette assignation permet de créer des variables et de les réutiliser plus tard. L’opérateur &lt;- est spécifique à R, mais il est possible d’utiliser = dans certains cas. Cependant, &lt;- est la convention généralement acceptée en R pour éviter toute ambiguïté.\n\nNommer les objets de manière explicite : Choisissez des noms explicites pour les objets afin de comprendre leur rôle dans le code.\n\n\n# Assignation d'une valeur\nmoyenne_hauteur &lt;- 170  # Hauteur moyenne en cm\n\n\nRéassignation des valeurs : Lorsque vous réassignez une valeur à un objet, la valeur précédente est perdue.\n\n\nx &lt;- 2\nx &lt;- 5  # La valeur de x est maintenant 5\n\n\nSuppression d’un objet : Pour libérer la mémoire, vous pouvez supprimer un objet avec rm().\n\n\nrm(x)  # Supprime l'objet x\n\n\n2.2.2.1 Exercice\n\nCréer et réassigner des objets : Créez un objet age et assignez-lui une valeur, puis modifiez cette valeur. Supprimez ensuite l’objet.\n\n\n\n\n2.2.3 Les différents types d’objets en R\nR utilise différents types d’objets pour stocker des données, chacun ayant ses spécificités.\n\nChaînes de caractères : Les chaînes de caractères sont délimitées par des guillemets.\n\n\nnom &lt;- \"Alice\"\nprint(nom)  # Affiche \"Alice\"\n\n[1] \"Alice\"\n\n\n\nVecteurs : Les vecteurs sont des objets qui contiennent plusieurs valeurs de même type.\n\n\n# Création d'un vecteur de tailles\ntailles &lt;- c(156, 164, 197, 147, 173)\ntailles_m &lt;- tailles / 100  # Conversion en mètres\n\nLes opérations peuvent être appliquées à l’ensemble des valeurs d’un vecteur.\n\ntailles_m + 0.1  # Ajoute 0,1 m à chaque valeur du vecteur\n\n[1] 1.66 1.74 2.07 1.57 1.83\n\n\n\n2.2.3.1 Exercice\n\nManipuler des vecteurs : Créez un vecteur de 5 poids en kilogrammes. Convertissez-les en grammes.\n\n\n\n\n2.2.4 Les tableaux de données (data.frame)\nLes data.frame sont des structures de données très courantes qui permettent de stocker des colonnes de types variés.\n\nCréation d’un data.frame : Combinez des vecteurs de même longueur pour créer un tableau de données.\n\n\nnoms &lt;- c(\"Alice\", \"Bob\", \"Charlie\")\nages &lt;- c(25, 30, 35)\ntableau &lt;- data.frame(noms, ages)\nprint(tableau)\n\n     noms ages\n1   Alice   25\n2     Bob   30\n3 Charlie   35\n\n\n\nAccéder aux colonnes : Utilisez $ pour accéder à une colonne spécifique d’un data.frame.\n\n\ntableau$ages  # Accède à la colonne 'ages'\n\n[1] 25 30 35\n\n\n\n2.2.4.1 Exercice\n\nCréer un data.frame : Créez un data.frame avec des noms, des âges et des tailles, puis affichez uniquement la colonne des tailles.\n\n\n\n\n2.2.5 Les noms d’objets\nLes noms des objets doivent être choisis avec soin pour qu’ils soient compréhensibles et explicites.\n\nConvention d’écriture : Utilisez le snake_case pour nommer vos objets (par exemple, moyenne_age).\nÉviter les majuscules et caractères spéciaux : Les majuscules peuvent prêter à confusion, car R est sensible à la casse.\n\n\n# Mauvaise pratique\nT1 &lt;- 100\n\n# Bonne pratique\ntemperature_moyenne &lt;- 100\n\n\n2.2.5.1 Exercice\n\nNommer des objets : Créez des objets pour représenter la température et la pression, en respectant les bonnes pratiques de nommage.\n\n\n\n\n2.2.6 Les fonctions\nLes fonctions sont des ensembles d’instructions qui effectuent des tâches spécifiques. Elles permettent de réutiliser du code facilement.\n\nCréer une fonction : Utilisez le mot-clé function pour créer une fonction.\n\n\n# Fonction qui additionne deux nombres\naddition &lt;- function(x, y) {\n  return(x + y)\n}\n\nresultat &lt;- addition(3, 4)  # Appel de la fonction\nprint(resultat)  # Affiche 7\n\n[1] 7\n\n\n\nFonctions natives et packages : De nombreuses fonctions sont intégrées à R, et d’autres sont disponibles via des packages additionnels.\n\n\n# Utilisation d'une fonction native\nsomme &lt;- sum(5, 10)\nprint(somme)  # Affiche 15\n\n[1] 15\n\n\n\n2.2.6.1 Exercice\n\nCréer une fonction : Créez une fonction qui calcule le carré d’un nombre et testez-la avec différentes valeurs.\n\n\n\n\n2.2.7 Les structures de contrôle : if, else, et les boucles\nLes structures de contrôle permettent d’exécuter du code conditionnellement ou de manière répétitive.\n\nConditions avec if et else : Les instructions if et else sont utilisées pour exécuter du code en fonction de conditions.\n\n\nx &lt;- 10\nif (x &gt; 5) {\n  print(\"x est supérieur à 5\")\n} else {\n  print(\"x est inférieur ou égal à 5\")\n}\n\n[1] \"x est supérieur à 5\"\n\n\nDans cet exemple, le message “x est supérieur à 5” sera affiché car la condition x &gt; 5 est vraie.\n\nBoucles for : Les boucles for permettent de répéter une série d’instructions un certain nombre de fois.\n\n\nfor (i in 1:5) {\n  print(paste(\"Itération :\", i))\n}\n\n[1] \"Itération : 1\"\n[1] \"Itération : 2\"\n[1] \"Itération : 3\"\n[1] \"Itération : 4\"\n[1] \"Itération : 5\"\n\n\nIci, la boucle for va exécuter l’instruction print() pour chaque valeur de i allant de 1 à 5.\n\n2.2.7.1 Exercice\n\nUtiliser une boucle for : Créez une boucle qui affiche les carrés des nombres de 1 à 10.\n\n\n\n\n2.2.8 Les valeurs manquantes\nLes valeurs manquantes (NA) sont courantes dans les jeux de données réels. Il est essentiel de savoir comment les gérer pour éviter des erreurs.\n\nGérer les valeurs manquantes : Utilisez na.rm = TRUE pour ignorer les NA dans des opérations.\n\n\nages &lt;- c(20, 30, NA, 40)\nmean(ages) # Renvoie une valeur manquante \n\n[1] NA\n\nmoyenne_ages &lt;- mean(ages, na.rm = TRUE)",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Fondamentaux pour l'utilisation de R</span>"
    ]
  },
  {
    "objectID": "02_bases_R.html#librairies-r",
    "href": "02_bases_R.html#librairies-r",
    "title": "2  Fondamentaux pour l’utilisation de R",
    "section": "2.3 Librairies R",
    "text": "2.3 Librairies R\nLes librairies R sont communément appelées “packages”. Plusieurs packages R sont utilisés pour ce projet. Les packages dans R sont des extensions de logiciels qui ajoutent des fonctionnalités spécifiques au langage R de base.\nIls sont conçus pour faciliter l’analyse de données, la visualisation, la modélisation statistique, et bien plus encore. Les packages sont comme des boîtes à outils virtuelles qui permettent aux utilisateurs d’effectuer des tâches analytiques avancées sans avoir à réinventer la roue à chaque fois. Ils permettent de gagner du temps et de se concentrer sur la résolution de problèmes spécifiques à son domaine d’étude, au lieu de vous soucier de la programmation de fonctions de base.\nLors de la rédaction de publications scientifiques, il est important de citer correctement les packages R utilisés dans votre analyse. Assurez-vous d’inclure le nom complet du package ainsi que le nom de son auteur ou des auteurs. Zotero et RStudio permettent aisément d’inclure ces citations dans votre analyse.\nLes autres packages mobilisés pour ce cours sont listés dans le bloc de code ci-dessous :\n\nlibrary(\"tidyverse\") # Une série de packages pour faciliter la manipulation de données\nlibrary(\"readxl\") # Pour lire les fichiers Excel (Carvalho et al. 2018)\nlibrary(\"gt\") # Pour des rendus graphiques harmonisés HTML et PDF/LaTeX\nlibrary(\"wdpar\") # Pour télécharger simplement la base d'aires protégées WDPA\n\n\n2.3.1 Le tidyverse\nLe “tidyverse” est un ensemble cohérent de packages R conçus pour la manipulation, la visualisation et l’analyse de données de manière cohérente et efficace. Il a été développé pour simplifier le flux de travail de l’analyse de données et pour rendre le code plus lisible et plus facile à comprendre.\n\n\n2.3.2 L’opérateur pipeline\nLe signe %&gt;% est un “tuyau”. On peut le lire à haute voix comme “ensuite”. Par exemple :\n\nlibrary(tidyverse)\n\na &lt;- 4\nb &lt;- 7\nc &lt;- 3\n\nd &lt;- a %&gt;%\n  addition(b) %&gt;%\n  addition(c)\n\n\n\n2.3.3 La préparation des données avec dplyr\nLe “tidyverse” comprend plusieurs packages populaires, notamment dplyr. Ce dernier est très utile pour épurer les données lorsque vous travaillez sur des tableaux (et donc sur des tables attributaires).\nIl est utilisé pour la manipulation de données, notamment le filtrage, la sélection, le regroupement et la création de nouvelles variables.\n\n# On commence par créer les variables (les colonnes du tableau)\nnoms &lt;- c(\"John\", \"Jack\", \"Cindy\", \"Samantha\")\nsexe &lt;- c(\"homme\", \"homme\", \"femme\", \"femme\")\nages &lt;- c(42, 57, 24, NA)\npoids &lt;- c(87, 73, NA, NA)\ntailles &lt;- c(174, 198, 192, 164)\n\n# On les rassemble dans un tableau \nma_table &lt;- data.frame(noms, sexe, ages, poids, tailles)\n\nma_table\n\n      noms  sexe ages poids tailles\n1     John homme   42    87     174\n2     Jack homme   57    73     198\n3    Cindy femme   24    NA     192\n4 Samantha femme   NA    NA     164\n\n# Un exemple qui combine ces opérations\nma_table %&gt;%\n  filter(!is.na(ages))\n\n   noms  sexe ages poids tailles\n1  John homme   42    87     174\n2  Jack homme   57    73     198\n3 Cindy femme   24    NA     192\n\nma_table %&gt;%\n  filter(!is.na(ages)) %&gt;%\n  select(sexe, ages, tailles, poids)\n\n   sexe ages tailles poids\n1 homme   42     174    87\n2 homme   57     198    73\n3 femme   24     192    NA\n\nma_table %&gt;%\n  filter(!is.na(ages)) %&gt;%\n  select(sexe, ages, tailles, poids) %&gt;%\n  group_by(sexe) %&gt;%\n  summarise(nb_pers = n())\n\n# A tibble: 2 × 2\n  sexe  nb_pers\n  &lt;chr&gt;   &lt;int&gt;\n1 femme       1\n2 homme       2\n\nma_table %&gt;%\n  filter(!is.na(ages)) %&gt;%\n  select(sexe, ages, tailles, poids) %&gt;%\n  group_by(sexe) %&gt;%\n  summarise(nb_pers = n(),\n            somme_poids = sum(poids, na.rm = TRUE),\n            taille_max = max(tailles, na.rm = TRUE),\n            age_moy = mean(ages, na.rm = TRUE))\n\n# A tibble: 2 × 5\n  sexe  nb_pers somme_poids taille_max age_moy\n  &lt;chr&gt;   &lt;int&gt;       &lt;dbl&gt;      &lt;dbl&gt;   &lt;dbl&gt;\n1 femme       1           0        192    24  \n2 homme       2         160        198    49.5\n\n\nVoici certaines des fonctions fondamentales de dplyr : - select : choisir des colonnes - filter : choisir des lignes - mutate : modifier des valeurs - group_by : regrouper les données par une ou plusieurs variables - summarise : créer des résumés sur les données\n\nExercice en groupe : à partir du tableau ventes_magasin, utilisez les fonctions précédentes et l’opérateur pipe pour réaliser les opérations suivantes :\n\nSélectionnez uniquement les colonnes produit, quantite, et prix_unitaire du data frame ventes_magasin.\nNe conservez que les ventes où la quantité vendue est supérieure à 5 unités.\nAjoutez une nouvelle colonne nommée montant qui représente le montant total de chaque vente (quantité multipliée par le prix unitaire) et ajoutez-la au data frame.\nCréez un nouveau tableau ventes_par_produit, regroupez les données par produit pour calculer la quantité totale vendue de chaque produit.\nComplétez ce tableau avec le montant total et le nombre de ventes.\n\n\n\n# Création du data frame ventes_magasin\nventes_magasin &lt;- data.frame(\n  produit = c(\"Produit A\", \"Produit B\", \"Produit A\", \"Produit C\", \"Produit B\",\n              \"Produit A\", \"Produit C\", \"Produit B\", \"Produit A\"),\n  quantite = c(8, 4, 12, 6, 7, 9, 3, 11, 5),\n  prix_unitaire = c(10, 15, 8, 12, 20, 10, 18, 14, 9),\n  date_vente = ymd( # Cette fonction interprète des dates year-month-day\n    c(\"2023-01-05\", \"2023-01-08\", \"2023-01-09\", \"2023-01-10\", \"2023-01-15\",\n      \"2023-01-20\", \"2023-01-25\", \"2023-01-30\", \"2023-02-02\"))\n  )\n\n\n\n2.3.4 Les jointures\nLes jointures permettent de fusionner deux tableaux par une variable d’identification (“clé”).\n\n# Tableau clients\nclients &lt;- data.frame(ID = c(1, 2, 3, 4),\n                      nom_client = c(\"Alice\", \"Bob\", \"Charlie\", \"David\"))\n\n# Tableau commandes\ncommandes &lt;- data.frame(ID = c(2, 3, 1, 4),\n                        montant = c(100, 150, 50, 200))\n\n# Jointure par ID\nresultat &lt;- inner_join(clients, commandes, by = \"ID\")\n\nCette opération exige toutefois que la variable d’identification soit écrite de manière identique dans les deux jeux de données.\nSupposons que l’on travaille sur les aires protégées à Madagascar et que l’on dispose de deux jeux de données provenant de sources différentes. On a alors des informations complémentaires que l’on souhaite fusionner en un seul tableau via le nom de l’aire protégée.\nIl faudra veiller à ce que les noms aient la même écriture (pas de différences avec des majuscules, des abréviations ou des noms raccourcis).",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Fondamentaux pour l'utilisation de R</span>"
    ]
  },
  {
    "objectID": "02_bases_R.html#import-de-données",
    "href": "02_bases_R.html#import-de-données",
    "title": "2  Fondamentaux pour l’utilisation de R",
    "section": "2.4 Import de données",
    "text": "2.4 Import de données\nPour cette section, nous allons développer l’importation de différents types de fichiers couramment utilisés dans R pour la manipulation et l’analyse de données. R permet d’importer et de manipuler divers formats de fichiers, notamment CSV, Excel et fichiers texte.\n\n2.4.1 Utilisation du menu interactif de RStudio\nAvant de passer à l’importation via du code, il est recommandé de se familiariser avec le menu interactif de RStudio pour importer des fichiers.\n\nPour importer un fichier, allez dans le panneau Files en bas à droite de l’interface RStudio.\nNaviguez vers le fichier data/AP_Vahatra.csv, faites un clic droit et sélectionnez Import Dataset.\nUn assistant d’import s’ouvrira, vous permettant de vérifier les données et de définir les options d’importation (séparateur, types de colonnes, etc.).\nUne fois satisfait, cliquez sur Import et examinez le code automatiquement généré par RStudio. Ce code pourra être utilisé et modifié par la suite pour automatiser l’importation des données.\n\n\n\n2.4.2 Types de fichiers et comment les importer en ligne de code\n\nFichiers CSV : Les fichiers CSV sont très populaires pour leur simplicité. Pour importer un fichier CSV, vous pouvez utiliser la fonction read.csv() ou read_csv() (package readr, partie du tidyverse).\n\n\nlibrary(readr)\n\nAP_Vahatra &lt;- read_csv(\"data/AP_Vahatra.csv\")\n\n2. Fichiers Excel : Pour importer des fichiers Excel, on peut utiliser le package readxl. La fonction read_xlsx() permet d’importer un fichier au format .xlsx.\n\nlibrary(readxl)\n\nMon_objet_R &lt;- read_xlsx(\"data/mon_fichier.xlsx\")\n\n3. Fichiers texte : Les fichiers texte peuvent être importés avec read.table() ou read_delim() (pour des délimiteurs personnalisés).\n\nAP_Vahatra &lt;- read_delim(\"data/mon_fichier.txt\", delim = \"\\t\")\n\n\n\n2.4.3 Exercice pratique\nPour vous familiariser avec ces différents formats, voici un petit exercice :\n\nImportez un fichier CSV présent dans le dossier data. Le fichier s’appelle AP_Vahatra.csv. Utilisez read_csv() pour l’importer dans un objet R.\nImportez un fichier Excel présent dans le dossier data. Le fichier s’appelle AP_Vahatra.xlsx. Utilisez read_xlsx() pour l’importer dans un objet R.\nImportez un fichier texte présent dans le dossier data. Le fichier s’appelle AP_Vahatra.txt. Utilisez read_delim() pour l’importer dans un objet R.\nAffichez les premières lignes avec la fonction head() des jeux de données pour vérifier l’importation correcte.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Fondamentaux pour l'utilisation de R</span>"
    ]
  },
  {
    "objectID": "02_bases_R.html#exploration-des-données-importées",
    "href": "02_bases_R.html#exploration-des-données-importées",
    "title": "2  Fondamentaux pour l’utilisation de R",
    "section": "2.5 Exploration des données importées",
    "text": "2.5 Exploration des données importées\nNous allons maintenant explorer le contenu d’AP_Vahatra.\n\nAfficher les noms des colonnes :\n\n\ncolnames(AP_Vahatra)\n\n [1] \"nom\"                \"cat_iucn\"           \"creation\"          \n [4] \"date_creation\"      \"date_modification\"  \"mention_changement\"\n [7] \"hectares\"           \"num_atlas_\"         \"full_name\"         \n[10] \"province\"           \"region\"             \"district\"          \n[13] \"gest_1\"             \"gest_2\"             \"type_ap\"           \n[16] \"an_creation\"        \"nom_wdpa\"           \"geometry\"          \n[19] \"rownum\"            \n\n\n\nSélectionner les 10 premières aires protégées et leur catégorie IUCN :\n\n\nAP_Vahatra %&gt;%\n  select(nom, cat_iucn) %&gt;%\n  filter(row_number() &lt;= 10)\n\n# A tibble: 10 × 2\n   nom                                     cat_iucn\n   &lt;chr&gt;                                   &lt;chr&gt;   \n 1 Agnakatrika                             VI      \n 2 Agnalazaha                              VI      \n 3 Ambatofotsy                             V       \n 4 Ambatotsirongorongo                     V       \n 5 Ambatovaky                              IV      \n 6 Ambohidray                              &lt;NA&gt;    \n 7 Ambohijanahary                          IV      \n 8 Ambohitantely                           IV      \n 9 Ambohitr'Antsingy Montagne des Français V       \n10 Amoron'i Onilahy                        V       \n\n\n\nExplorer les dates de création et de modification :\n\n\nAP_Vahatra %&gt;%\n  select(nom, date_creation, date_modification) %&gt;%\n  filter(!is.na(date_creation)) %&gt;%\n  arrange(date_creation)\n\n# A tibble: 98 × 3\n   nom            date_creation       date_modification  \n   &lt;chr&gt;          &lt;dttm&gt;              &lt;dttm&gt;             \n 1 Lokobe         1927-12-31 00:00:00 2011-07-06 00:00:00\n 2 Analamerana    1956-02-20 00:00:00 2015-04-21 00:00:00\n 3 Ankarana       1956-02-20 00:00:00 2015-04-21 00:00:00\n 4 Bora           1956-02-20 00:00:00 NA                 \n 5 Manongarivo    1956-02-20 00:00:00 NA                 \n 6 Marotandrano   1956-02-20 00:00:00 2015-04-28 00:00:00\n 7 Bemarivo       1956-09-10 00:00:00 NA                 \n 8 Kasijy         1956-09-10 00:00:00 NA                 \n 9 Ambatovaky     1958-10-28 00:00:00 2015-04-28 00:00:00\n10 Ambohijanahary 1958-10-28 00:00:00 NA                 \n# ℹ 88 more rows\n\n\n\nCalculer la superficie totale des aires protégées :\n\n\nAP_Vahatra %&gt;%\n  summarise(superficie_totale = sum(hectares, na.rm = TRUE))\n\n# A tibble: 1 × 1\n  superficie_totale\n              &lt;dbl&gt;\n1          6372482.\n\n\n\nLister les aires protégées gérées par “Madagascar National Parks” :\n\n\nAP_Vahatra %&gt;%\n  filter(gest_1 == \"Madagascar National Parks\") %&gt;%\n  select(nom, gest_1)\n\n# A tibble: 38 × 2\n   nom              gest_1                   \n   &lt;chr&gt;            &lt;chr&gt;                    \n 1 Ambatovaky       Madagascar National Parks\n 2 Ambohitantely    Madagascar National Parks\n 3 Analamazaotra    Madagascar National Parks\n 4 Analamerana      Madagascar National Parks\n 5 Andohahela       Madagascar National Parks\n 6 Andranomena      Madagascar National Parks\n 7 Anjanaharibe Sud Madagascar National Parks\n 8 Ankarafantsika   Madagascar National Parks\n 9 Ankarana         Madagascar National Parks\n10 Baie de Baly     Madagascar National Parks\n# ℹ 28 more rows\n\n\n\nObtenir des statistiques descriptives sur la superficie des aires protégées :\n\n\nAP_Vahatra %&gt;%\n  summarise(superficie_moyenne = mean(hectares, na.rm = TRUE),\n            superficie_mediane = median(hectares, na.rm = TRUE),\n            superficie_max = max(hectares, na.rm = TRUE),\n            superficie_min = min(hectares, na.rm = TRUE))\n\n# A tibble: 1 × 4\n  superficie_moyenne superficie_mediane superficie_max superficie_min\n               &lt;dbl&gt;              &lt;dbl&gt;          &lt;dbl&gt;          &lt;dbl&gt;\n1             65025.             24963.        426594.           225.\n\n\n\n2.5.1 Exercice supplémentaire\nPour cet exercice, utilisez les données AP_Vahatra que vous avez importées pour produire les statistiques suivantes :\n\nFiltrez les aires protégées dont la catégorie IUCN est “II” et affichez uniquement leurs noms.\nAjoutez une colonne superficie_km2 à AP_Vahatra en convertissant la valeur hectares en kilomètres carrés.\nTriez les données par superficie_km2 de manière décroissante.\nTrouvez le nom des 3 plus grandes aires protégées\nCalculez la superficie totale de toutes les aires protégées\nProduisez un résumé statistique (summary()) des valeurs de superficie_km2.\nFiltrez les aires protégées ayant une superficie supérieure ou égale au 3ème quartile et calculez leur nombre.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Fondamentaux pour l'utilisation de R</span>"
    ]
  },
  {
    "objectID": "02_bases_R.html#production-de-tableaux-avec-r",
    "href": "02_bases_R.html#production-de-tableaux-avec-r",
    "title": "2  Fondamentaux pour l’utilisation de R",
    "section": "2.6 Production de tableaux avec R",
    "text": "2.6 Production de tableaux avec R\nLa fonction gt() permet d’obtenir des tableaux bien formatés, idéals pour présenter des résultats de manière claire et esthétique. Elle est particulièrement utile pour la création de rapports et la présentation de données tabulaires de manière attrayante. Voici quelques-unes des fonctions essentielles de gt :\n\ncols_label() : Cette fonction permet de renommer les colonnes pour leur donner des titres plus explicites.\ntab_header() : Elle permet d’ajouter un titre et un sous-titre au tableau, facilitant ainsi la compréhension de ce que le tableau représente.\nfmt_number() : Cette fonction permet de formater les nombres, par exemple en définissant le nombre de décimales.\ntab_source_note() : Elle permet d’ajouter une note de source au tableau, indiquant d’où proviennent les données.\n\n\n2.6.1 Exemple d’utilisation de gt\nVoici un exemple d’utilisation de gt pour résumer les superficies des aires protégées par catégorie IUCN.\n\n# On va dabord convertir les superficies en hectares dans une nouvelle colonne\nAP_Vahatra &lt;- AP_Vahatra %&gt;%\n  mutate(superficie_km2 = hectares * 0.01)\n\n\n# Calcul des superficies totales pour chaque catégorie IUCN\nAP_Vahatra_iucn &lt;- AP_Vahatra %&gt;%\n  mutate(superficie_km2 = hectares * 0.01) %&gt;%\n  filter(!is.na(cat_iucn)) %&gt;%\n  group_by(cat_iucn) %&gt;%\n  summarise(superficie_totale = sum(superficie_km2))\n\n# Production du tableau\nAP_Vahatra_iucn %&gt;%\n  gt() %&gt;%\n  cols_label(cat_iucn = \"Catégorie IUCN\",\n             superficie_totale = \"Superficie totale (km²)\") %&gt;%\n  tab_header(\n    title = \"Aires protégées de Madagascar : superficies par catégorie IUCN\") %&gt;%\n  tab_source_note(\"Source : données de l'association Vahatra\") %&gt;%\n  fmt_number(decimals = 2)\n\n\n\n\n\n\n\nAires protégées de Madagascar : superficies par catégorie IUCN\n\n\nCatégorie IUCN\nSuperficie totale (km²)\n\n\n\n\nI\n22.40\n\n\nII\n25,380.56\n\n\nIII\n44.17\n\n\nIV\n4,138.88\n\n\nV\n22,752.70\n\n\nVI\n8,265.72\n\n\n\nSource : données de l'association Vahatra\n\n\n\n\n\n\n\n\n\n\n2.6.2 Superficie cumulée par année de création\nAvant de créer un graphique en nuages de points, nous devons préparer un tableau qui résume la superficie cumulée des aires protégées en fonction de leur année de création.\n\nAP_superficie_annees &lt;- AP_Vahatra %&gt;%\n  group_by(an_creation) %&gt;%\n  summarise(superficie_annuelle = sum(superficie_km2, na.rm = TRUE)) %&gt;%\n  arrange(an_creation) %&gt;%\n  mutate(superficie_cumulée = cumsum(superficie_annuelle))\n\n\n\n2.6.3 Exercice : Créer un tableau synthétique\n\nRésumer la superficie cumulée par année de création : Utilisez gt() pour présenter les résultats de AP_superficie_annees de manière claire et lisible.\nAjouter des colonnes d’explication : Créez des colonnes qui expliquent chaque étape du processus (par exemple, année de création, superficie annuelle ajoutée, superficie cumulée).\nAjouter un titre et une note de source : Le tableau devrait inclure un titre explicite et une note de source, similaire à l’exemple précédent.\n\nCes étapes vous aideront à présenter les données de manière élégante et à faciliter la compréhension des tendances liées à la création des aires protégées.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Fondamentaux pour l'utilisation de R</span>"
    ]
  },
  {
    "objectID": "02_bases_R.html#production-de-graphiques-avec-ggplot2",
    "href": "02_bases_R.html#production-de-graphiques-avec-ggplot2",
    "title": "2  Fondamentaux pour l’utilisation de R",
    "section": "2.7 Production de graphiques avec ggplot2",
    "text": "2.7 Production de graphiques avec ggplot2\nPour produire des graphiques de qualité avec R, nous utilisons souvent le package ggplot2. Ce package repose sur une approche appelée “la grammaire des graphiques”. Cette grammaire est une façon systématique de construire des visualisations, en combinant différents composants graphiques, comme des axes, des légendes, des points, des lignes, etc. Elle offre une grande flexibilité et permet de créer des graphiques complexes de manière progressive.\n\n2.7.1 Philosophie de la “grammaire des graphiques”\nLa grammaire des graphiques est une méthode de pensée pour créer des visualisations. Elle repose sur l’idée que tout graphique peut être décomposé en une série de couches. Par exemple :\n\nDonnées : La première étape consiste à spécifier les données à utiliser pour le graphique.\nAesthetic mappings (Mappings esthétiques) : Cela consiste à indiquer comment les variables des données seront représentées visuellement, par exemple, quel axe représente quelle variable, ou quelles couleurs représentent quelles catégories.\nGeometries (Géométries) : Chaque graphique est composé de formes géométriques, comme des points, des lignes, des barres, etc. Ces géométries déterminent la manière dont les données seront visualisées.\nFacettes : Cette étape permet de subdiviser le graphique en plusieurs sous-graphiques basés sur une variable, facilitant ainsi la comparaison entre catégories.\nStatistiques : Certaines visualisations nécessitent des transformations statistiques, comme l’ajout de moyennes, de tendances ou d’intervalles de confiance.\nCoordonnées : Il s’agit de définir les systèmes de coordonnées, tels que les axes cartésiens ou polaires.\nThème : Enfin, le thème est utilisé pour définir l’apparence générale du graphique, par exemple, les couleurs de fond, la taille des polices, etc.\n\nEn combinant ces différentes couches, ggplot2 permet de construire des visualisations claires et personnalisées, adaptées aux besoins spécifiques de l’analyse.\n\n\n2.7.2 Introduction à ggplot2\nLe package ggplot2 suit cette logique en permettant d’ajouter chaque composant graphique avec le signe +. Voici une approche progressive pour comprendre ggplot2 :\n\nImporter le package et les données :\n\n\nlibrary(ggplot2)\n# On suppose que AP_superficie_annees est déjà créé\n\n\nCréer la base du graphique :\n\nLa première étape consiste à spécifier les données et les mappings esthétiques. Par exemple, nous allons indiquer que l’axe des abscisses (x) représente l’année de création (an_creation) et l’axe des ordonnées (y) représente la superficie cumulée (superficie_cumulée).\n\nggplot(data = AP_superficie_annees, aes(x = an_creation, y = superficie_cumulée))\n\n\n\n\n\n\n\n\n\nAjouter des géométries :\n\nPour visualiser les données, nous ajoutons des points (geom_point()) et des lignes (geom_line()).\n\nggplot(data = AP_superficie_annees, aes(x = an_creation, y = superficie_cumulée)) +\n  geom_point() +\n  geom_line()\n\n\n\n\n\n\n\n\n\nAjouter des labels :\n\nPour rendre le graphique plus compréhensible, nous ajoutons des labels pour les axes et un titre.\n\nggplot(data = AP_superficie_annees, aes(x = an_creation, y = superficie_cumulée)) +\n  geom_point() +\n  geom_line() +\n  labs(x = \"Année\", y = \"Superficie cumulée (km²)\",\n       title = \"Superficie cumulée en fonction de l'année de création\")\n\n\n\n\n\n\n\n\n\nAppliquer un thème :\n\nLe thème permet de personnaliser l’apparence générale du graphique. Ici, nous utilisons theme_minimal() pour une apparence épurée.\n\nggplot(data = AP_superficie_annees, aes(x = an_creation, y = superficie_cumulée)) +\n  geom_point() +\n  geom_line() +\n  labs(x = \"Année\", y = \"Superficie cumulée (km²)\",\n       title = \"Superficie cumulée en fonction de l'année de création\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n2.7.3 Exercice : Créer un graphique avec ggplot2\n\nCréer un graphique en nuages de points : Utilisez ggplot2 pour créer un graphique qui montre la superficie annuelle des aires protégées en fonction de leur année de création.\nAjouter des lignes de tendance : Ajoutez une ligne de tendance (geom_smooth()) pour montrer l’évolution générale de la superficie annuelle au fil du temps.\nFacetter par catégorie IUCN : Utilisez facet_wrap() pour créer des sous-graphiques qui montrent la superficie cumulée par année de création pour chaque catégorie IUCN.\n\nCes étapes vous permettront de comprendre progressivement comment construire des graphiques en utilisant la grammaire des graphiques, et d’explorer différentes façons de visualiser vos données.\n\n\n\n\nBarnier, Julien. 2022. “Introduction à R Et Au Tidyverse.” https://juba.github.io/tidyverse/index.html.\n\n\nGaliana, Lino, and Olivier Meslin, eds. 2022. “utilitR: Documentation Collaborative Sur r.” https://www.book.utilitr.org/.\n\n\nGörgen, Darius A., and Om Prakash Bhandari. 2022. Mapme.biodiversity: Efficient Monitoring of Global Biodiversity Portfolios. https://CRAN.R-project.org/package=mapme.biodiversity.\n\n\nGrolemund, Garrett, and Hadley Wickham. 2022. R for Data Science: Import, Tidy, Transform, Visualize, and Model Data. 1st edition. Sebastopol, CA: O’Reilly Media. https://r4ds.had.co.nz/.\n\n\nLarmarange, Joseph. 2024. Guide-r : Guide Pour l’analyse de Données d’enquêtes Avec r. https://larmarange.github.io/guide-R/.\n\n\nLovelace, Robin, Jakub Nowosad, and Jannes Muenchow. 2022. Geocomputation with R. Boca Raton London New York: Routledge. https://geocompr.robinlovelace.net/.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Fondamentaux pour l'utilisation de R</span>"
    ]
  },
  {
    "objectID": "03_geodata.html",
    "href": "03_geodata.html",
    "title": "3  Données spatiales : types et importation",
    "section": "",
    "text": "3.1 Types de données spatiales\nLes données spatiales peuvent être regroupées en deux types principaux :",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Données spatiales : types et importation</span>"
    ]
  },
  {
    "objectID": "03_geodata.html#types-de-données-spatiales",
    "href": "03_geodata.html#types-de-données-spatiales",
    "title": "3  Données spatiales : types et importation",
    "section": "",
    "text": "Vecteur : Les données vectorielles représentent des entités géographiques par des points, des lignes, et des polygones. Chaque entité spatiale est associée à des attributs qui peuvent être vus comme un tableau de données lié à ces entités. Par exemple : les frontières administratives, les routes, les parcs naturels.\nRaster : Les données raster sont représentées par une grille de pixels, où chaque cellule contient une valeur. Ce type de donnée est généralement utilisé pour les données continues, comme l’altitude, la température, ou la couverture forestière.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Données spatiales : types et importation</span>"
    ]
  },
  {
    "objectID": "03_geodata.html#données-vectorielles",
    "href": "03_geodata.html#données-vectorielles",
    "title": "3  Données spatiales : types et importation",
    "section": "3.2 Données vectorielles",
    "text": "3.2 Données vectorielles\n\n3.2.1 Importation des données vectorielles avec sf\nPour illustrer l’importation de données vectorielles, nous allons utiliser le package sf, qui est une librairie puissante pour la manipulation des données spatiales vectorielles en R.\n\nCharger les Données : Nous allons commencer par charger un fichier GeoJSON qui contient des informations sur les aires protégées de Madagascar.\n\n\n\nCode\nlibrary(sf)\nlibrary(tidyverse)\nlibrary(tmap)\nlibrary(geodata)\nlibrary(terra)\n\n# Importer le fichier GeoJSON\nAP_Vahatra &lt;- st_read(\"data/AP_Vahatra.geojson\")\n\n\nReading layer `AP_Vahatra' from data source \n  `/home/onyxia/work/mapme_impact_training/data/AP_Vahatra.geojson' \n  using driver `GeoJSON'\nSimple feature collection with 98 features and 16 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 43.25742 ymin: -25.60502 xmax: 50.47724 ymax: -11.98301\nGeodetic CRS:  WGS 84\n\n\n\nExplorer les Données : Explorons le contenu de ce fichier pour comprendre sa structure et ses attributs. Vous pouvez également utiliser le menu contextuel de RStudio pour ouvrir et examiner les données de manière interactive.\n\n\n\nCode\n# Afficher les premières lignes de l'objet spatial\nhead(AP_Vahatra)\n\n\nSimple feature collection with 6 features and 16 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 44.35118 ymin: -25.12034 xmax: 48.32607 ymax: -15.59973\nGeodetic CRS:  WGS 84\n                           nom cat_iucn                           creation\n1          Ambatotsirongorongo        V Décret n°2015-792 du 28 avril 2015\n2                   Ambohidray     &lt;NA&gt;    Décret n°2015-808 du 5 mai 2015\n3               Ambohijanahary       IV    Créée depuis le 28 octobre 1958\n4                     Bemarivo       IV         Créée le 10 septembre 1956\n5 Corridor Forestier Bongolava     &lt;NA&gt; Décret n°2015-790 du 28 avril 2015\n6                       Kasijy       IV          Créée le 10 setembre 1956\n  date_creation date_modification mention_changement  hectares num_atlas_\n1    2015-04-28              &lt;NA&gt;              FALSE  1030.048         62\n2    2015-05-05              &lt;NA&gt;              FALSE  1241.048         38\n3    1958-10-28              &lt;NA&gt;              FALSE 24302.027         72\n4    1956-09-10              &lt;NA&gt;              FALSE 12046.314         79\n5    2015-04-28              &lt;NA&gt;              FALSE 60589.816         63\n6    1956-09-10              &lt;NA&gt;              FALSE 22956.386         70\n                                                   full_name\n1                   Réserve Spéciale d'Ambatotsirongorongo\\n\n2                        Nouvelle Aire Protégée d'Ambohidray\n3                        Réserve Spéciale d'Ambohijanahary\\n\n4                               Réserve Spéciale de Bemarivo\n5 Paysage Harmonieux Protégé du Corridor Forestier Bongolava\n6                                 Réserve Spéciale de Kasijy\n              province           region                         district\n1              Toliary            Anosy      Taolagnaro (Fort Dauphin)\\n\n2            Toamasina  Alaotra Mangoro                        Moramanga\n3 Mahajanga, Toliary\\n Melaky, Menabe\\n        Morafenobe, Miandrivazo\\n\n4            Mahajanga           Melaky            Besalampy, Maintirano\n5            Mahajanga            Sofia Mampikony, Boriziny (Port Bergé)\n6            Mahajanga        Betsiboka                         Kandreho\n                                                                    gest_1\n1              Ministère de l'Environnement, de l'Ecologie et des Forêts\\n\n2                            Département de Biologie et Ecologie Végétales\n3 Sauvegarde de l'Environnement et développement Intégré de Magadagascar\\n\n4                Ministère de l'Environnement, de l'Ecologie et des Forêts\n5                                          Fikambananana Bongolava Maintso\n6                Ministère de l'Environnement, de l'Ecologie et des Forêts\n   gest_2     type_ap an_creation                       geometry\n1  MEEF\\n TERRESTRE\\n        2015 MULTIPOLYGON (((46.78478 -2...\n2    DBEV   TERRESTRE        2015 MULTIPOLYGON (((48.29791 -1...\n3 SEDIM\\n TERRESTRE\\n        1958 MULTIPOLYGON (((45.43863 -1...\n4    MEEF   TERRESTRE        1956 MULTIPOLYGON (((44.4565 -17...\n5     FBM   TERRESTRE        2015 MULTIPOLYGON (((47.60184 -1...\n6    MEEF   TERRESTRE        1956 MULTIPOLYGON (((45.96836 -1...\n\n\nCode\n# Voir la structure des attributs\nstr(AP_Vahatra)\n\n\nClasses 'sf' and 'data.frame':  98 obs. of  17 variables:\n $ nom               : chr  \"Ambatotsirongorongo\" \"Ambohidray\" \"Ambohijanahary\" \"Bemarivo\" ...\n $ cat_iucn          : chr  \"V\" NA \"IV\" \"IV\" ...\n $ creation          : chr  \"Décret n°2015-792 du 28 avril 2015\" \"Décret n°2015-808 du 5 mai 2015\" \"Créée depuis le 28 octobre 1958\" \"Créée le 10 septembre 1956\" ...\n $ date_creation     : Date, format: \"2015-04-28\" \"2015-05-05\" ...\n $ date_modification : Date, format: NA NA ...\n $ mention_changement: logi  FALSE FALSE FALSE FALSE FALSE FALSE ...\n $ hectares          : num  1030 1241 24302 12046 60590 ...\n $ num_atlas_        : int  62 38 72 79 63 70 93 66 88 56 ...\n $ full_name         : chr  \"Réserve Spéciale d'Ambatotsirongorongo\\n\" \"Nouvelle Aire Protégée d'Ambohidray\" \"Réserve Spéciale d'Ambohijanahary\\n\" \"Réserve Spéciale de Bemarivo\" ...\n $ province          : chr  \"Toliary\" \"Toamasina\" \"Mahajanga, Toliary\\n\" \"Mahajanga\" ...\n $ region            : chr  \"Anosy\" \"Alaotra Mangoro\" \"Melaky, Menabe\\n\" \"Melaky\" ...\n $ district          : chr  \"Taolagnaro (Fort Dauphin)\\n\" \"Moramanga\" \"Morafenobe, Miandrivazo\\n\" \"Besalampy, Maintirano\" ...\n $ gest_1            : chr  \"Ministère de l'Environnement, de l'Ecologie et des Forêts\\n\" \"Département de Biologie et Ecologie Végétales\" \"Sauvegarde de l'Environnement et développement Intégré de Magadagascar\\n\" \"Ministère de l'Environnement, de l'Ecologie et des Forêts\" ...\n $ gest_2            : chr  \"MEEF\\n\" \"DBEV\" \"SEDIM\\n\" \"MEEF\" ...\n $ type_ap           : chr  \"TERRESTRE\\n\" \"TERRESTRE\" \"TERRESTRE\\n\" \"TERRESTRE\" ...\n $ an_creation       : num  2015 2015 1958 1956 2015 ...\n $ geometry          :sfc_MULTIPOLYGON of length 98; first list element: List of 1\n  ..$ :List of 1\n  .. ..$ : num [1:272, 1:2] 46.8 46.8 46.8 46.8 46.8 ...\n  ..- attr(*, \"class\")= chr [1:3] \"XY\" \"MULTIPOLYGON\" \"sfg\"\n - attr(*, \"sf_column\")= chr \"geometry\"\n - attr(*, \"agr\")= Factor w/ 3 levels \"constant\",\"aggregate\",..: NA NA NA NA NA NA NA NA NA NA ...\n  ..- attr(*, \"names\")= chr [1:16] \"nom\" \"cat_iucn\" \"creation\" \"date_creation\" ...\n\n\nCode\n# Ouvrir les données dans la vue interactive de RStudio\n# View(AP_Vahatra)\n\n\n\nVisualisation Initiale avec tmap : Utilisons tmap pour visualiser les aires protégées et avoir une première idée de leur distribution géographique.\n\n\n\nCode\n# Mode interactif pour explorer les données\ntmap_mode(\"view\")\n\n# Créer une carte interactive des aires protégées\ntm_shape(AP_Vahatra) +\n  tm_borders() +\n  tm_fill(\"cat_iucn\", title = \"Catégorie IUCN\")\n\n\n\n\n\n\n\n\n3.2.2 Formats usuels de données vectorielles\nLes données vectorielles peuvent être enregistrées dans différents formats, tels que :\n\nGeoJSON : Format ouvert et largement utilisé pour le partage de données spatiales sur le web. Il est basé sur une structure JSON, ce qui le rend lisible pour les humains.\n\nPour illustrer ce format, nous pouvons ouvrir le fichier AP_Vahatra.geojson dans un éditeur de texte. Vous remarquerez une structure JSON qui contient les coordonnées géographiques ainsi que les attributs associés à chaque entité.\n\nShapefile : Convertissons le fichier GeoJSON en shapefile pour voir comment les données sont structurées dans ce format très couramment utilisé.\n\n\n\nCode\n# On crée un dossier pour l'export\ndir.create(\"output\")\n# Enregistrer l'objet en tant que shapefile dans un sous-dossier de data\nst_write(AP_Vahatra, \"output/AP_Vahatra_shapefile.shp\", \n         append = FALSE,\n         layer_options = \"ENCODING=UTF-8\")\n\n\nDeleting layer `AP_Vahatra_shapefile' using driver `ESRI Shapefile'\nWriting layer `AP_Vahatra_shapefile' to data source \n  `output/AP_Vahatra_shapefile.shp' using driver `ESRI Shapefile'\noptions:        ENCODING=UTF-8 \nWriting 98 features with 16 fields and geometry type Multi Polygon.\n\n\nUn shapefile est en fait constitué de plusieurs fichiers (.shp, .shx, .dbf, .prj, etc.) qui doivent être conservés ensemble pour garantir l’intégrité des données. Chaque fichier a un rôle spécifique :\n\n.shp : Contient la géométrie des entités (points, lignes, polygones).\n.shx : Index spatial permettant d’accéder rapidement aux entités.\n.dbf : Base de données associée contenant les attributs des entités.\n.prj : Contient les informations relatives à la projection cartographique, permettant de définir le système de coordonnées des données.\n\nCes fichiers doivent non seulement être gardés ensemble, mais aussi porter exactement le même nom (à l’exception de l’extension).\n\nInstruction : Ouvrez le dossier output dans votre explorateur de fichiers pour observer les différents fichiers qui composent le shapefile.\n\n\nLire le Shapefile : Importons le shapefile nouvellement créé et vérifions qu’il est identique à l’objet d’origine.\n\n\n\nCode\n# Importer le shapefile\nAP_Vahatra_shp &lt;- st_read(\"output/AP_Vahatra_shapefile.shp\", quiet = TRUE) \n\n# Vérifier que les deux objets sont identiques\nidentical(AP_Vahatra, AP_Vahatra_shp)\n\n\n[1] FALSE\n\n\n\nLes objets ne sont plus exactement les mêmes. Voyez-vous pourquoi ?\n\nOutre le GeoJSON et le Shapefile, d’autres formats de données vectorielles incluent :\n\nKML (Keyhole Markup Language) : Utilisé principalement par Google Earth.\nGPKG (GeoPackage) : Un format basé sur SQLite, qui est de plus en plus populaire pour stocker des données spatiales.\nGML (Geography Markup Language) : Format XML utilisé pour échanger des données géospatiales.\nRDS (Format Natif R) : Format utilisé pour enregistrer des objets R directement, ce qui permet une manipulation rapide et facile des données spatiales dans R.\n\n\n\n3.2.3 Exploration des Données GADM\nPour illustrer l’accès aux données spatiales administratives, nous allons utiliser les données GADM (Global Administrative Areas). Ces données sont disponibles à différents niveaux administratifs (niveaux 0, 1, 2, etc.). Voici ce que nous allons faire :\n\nTéléchargement manuel : Rendez-vous sur le site https://gadm.org/ et explorez les différentes options de téléchargement des données administratives. Cela vous permettra de vous familiariser avec les types de niveaux disponibles.\nTéléchargement via R : Utilisons la fonction gadm() du package geodata pour obtenir directement les données dans R.\n\n\n\nCode\n# Télécharger les données GADM pour Madagascar au niveau administratif 0\ngadm_mada0 &lt;- gadm(country = \"Madagascar\", level = 0, path = \"data\") %&gt;%\n  st_as_sf() # Pour transformer en vecteur\n\n\nExercices :\n\nVisualisez les données gadm_mada0 téléchargées avec tmap. De quel niveau administratif s’agit-il ?\nEn utilisant les autres niveaux administratifs disponibles (1, 2, 3, 4), déduisez à quoi correspond chaque niveau dans la hiérarchie administrative de Madagascar.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Données spatiales : types et importation</span>"
    ]
  },
  {
    "objectID": "03_geodata.html#données-en-raster",
    "href": "03_geodata.html#données-en-raster",
    "title": "3  Données spatiales : types et importation",
    "section": "3.3 Données en raster",
    "text": "3.3 Données en raster\n\n3.3.1 Importation de données raster avec terra\nLes données raster sont constituées d’une grille de pixels, chaque pixel ayant une valeur. Ce type de donnée est généralement utilisé pour représenter des phénomènes continus tels que la couverture forestière, l’altitude, ou la précipitation. Les données raster sont souvent dérivées d’images satellitaires ou de relevés aériens, et peuvent varier en résolution (taille des pixels) et en échelle.\nIl existe deux catégories principales de données raster :\n\nImages Satellitaires : Ce sont des images prises à partir de satellites, telles que celles fournies par Sentinel-2 ou Landsat (gratuites, à moyenne résolution) ou encore Pléiades (payantes, à haute résolution).\nProduits Prétransformés : Ces données sont déjà traitées pour extraire certaines informations pertinentes (par exemple, la couverture forestière, les précipitations mensuelles, l’altitude). Ces produits sont souvent préférés car ils sont directement exploitables.\n\nVoici quelques exemples de produits prétransformés disponibles, qui peuvent être utiles dans vos analyses :\n\naccessibility_2000 : Accessibilité pour l’année 2000\nbiodiversity_intactness_index : Indice d’intactité de la biodiversité\ngfw_treecover : Pourcentage de couverture arborée\nworldclim_max_temperature : Température maximale mensuelle (1960 - 2018)\nsoilgrids : Propriétés du sol modélisées à l’échelle globale\n\nCes ressources, parmi d’autres, sont disponibles pour l’analyse et fournissent des données spatiales à différentes résolutions et pour différents indicateurs.\nPour explorer concrètement une donnée raster, nous allons travailler avec une tuile de la base de données Global Forest Change (GFC). Ces données sont disponibles en ligne sur Global Forest Change 2023. Nous utiliserons la tuile 10S, 50E, qui couvre une partie de la côte est de Madagascar, près du parc national de Masoala. Cette tuile est relativement légère car elle comprend principalement des zones marines.\nLa tuile préchargée est disponible sous : data/Hansen_GFC-2023-v1.11_treecover2000_10S_050E.tif.\n\nCharger et Observer la Tuile Raster : Utilisons le package terra pour manipuler les données raster dans R.\n\n\n\nCode\n# Charger la tuile raster\ngfc_raster &lt;- rast(\"data/Hansen_GFC-2023-v1.11_treecover2000_10S_050E.tif\")\n\n# Extraire la bounding box du raster en tant que SpatVector\nraster_bbox &lt;- as.polygons(ext(gfc_raster), crs = crs(gfc_raster)) %&gt;%\n  st_as_sf()\n\n# Calculer l'intersection entre la bbox du raster et gadm_mada0\nintersection &lt;- st_intersection(raster_bbox, gadm_mada0)\n\n\n# Réduire l'étendue du raster avec crop() en utilisant l'emprise de Madagascar\ngfc_raster_crop &lt;- crop(gfc_raster, intersection)\n\n# Appliquer mask() pour ne garder que la partie terrestre\ngfc_raster_mada &lt;- mask(gfc_raster_crop, intersection)\n\n\n# Visualiser la donnée raster\nplot(gfc_raster_mada, main = \"Couvert forestier en 2000 (Tuile 10S, 50E)\")\n\n\n\n\n\n\n\n\n\nLa fonction rast() permet de charger un fichier raster, et plot() permet d’avoir une visualisation simple de la couverture forestière de l’année 2000 pour la zone concernée. Observez la résolution de la grille ainsi que les valeurs attribuées à chaque pixel, qui représentent ici la proportion de couverture arborée.\n\nVisualisation avec tmap : Utilisons maintenant tmap en mode “view” pour représenter les données raster et colorer la carte en fonction du pourcentage de couvert forestier.\n\n\n\nCode\n# Mode interactif pour explorer les données\ntmap_mode(\"view\") # Le mode 'view' est utilisé ici pour une visualisation interactive des données spatiales, permettant une exploration dynamique avec des outils de navigation, contrairement au mode 'plot' qui produit une carte statique.\n\n# Créer une carte interactive de la couverture forestière\ntm_shape(gfc_raster_mada) +\n  tm_raster(style = \"cont\", palette = \"Greens\", title = \"Couvert Forestier (% en 2000)\")\n\n\n\n\n\n\n\n\n3.3.2 Formats de données raster\nComme pour les données vectorielles, les données raster peuvent être enregistrées dans différents formats. Voici quelques-uns des formats les plus courants :\n\nGeoTIFF : Format très utilisé pour les données raster, car il permet de stocker des informations géoréférencées (coordonnées, projection).\n.img : Format souvent utilisé par le logiciel ERDAS pour les données raster.\nNetCDF : Format flexible utilisé pour stocker des données multidimensionnelles (ex., temps, altitude).\nRDS (Format Natif R) : Permet d’enregistrer un objet R directement, ce qui est très pratique pour conserver les paramètres et les métadonnées associées.\n\n\n\n3.3.3 Exercice : exploration manuelle et via R\n\nExploration Manuelle : Rendez-vous sur le site Global Forest Change 2023, et téléchargez une tuile de votre choix. Essayez de comprendre la structure des fichiers téléchargés et leur signification.\nChargement avec R : Utilisez la fonction rast() du package terra pour charger la tuile que vous avez téléchargée, puis affichez-la avec plot(). Quels types d’informations pouvez-vous en déduire ?\nDécrire les Différents Formats : En fonction de ce que vous avez appris, décrivez les différents formats de données raster que vous avez rencontrés, et discutez des avantages de chaque format en termes de stockage, de compatibilité, et d’utilisation dans R.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Données spatiales : types et importation</span>"
    ]
  },
  {
    "objectID": "03_geodata.html#opérations-spatiales-avec-le-package-sf",
    "href": "03_geodata.html#opérations-spatiales-avec-le-package-sf",
    "title": "3  Données spatiales : types et importation",
    "section": "3.4 Opérations spatiales avec le package sf",
    "text": "3.4 Opérations spatiales avec le package sf\n\n3.4.1 Introduction aux opérations spatiales\nLes opérations spatiales sont des manipulations qui permettent de croiser, combiner, séparer ou analyser des données géographiques. Ces opérations sont essentielles pour explorer les relations spatiales entre différents objets géographiques, par exemple : trouver les aires qui se chevauchent, calculer des distances, ou encore créer des zones d’influence (buffers).\nDans cette section, nous allons nous familiariser avec quelques opérations spatiales de base à l’aide du package sf, un outil puissant pour manipuler les données géographiques dans R.\n\n\n3.4.2 Types d’opérations spatiales\n\n3.4.2.1 Intersection\nL’intersection permet de trouver la zone commune entre deux entités géographiques. Nous avons déjà utilisé cette opération pour découper le raster de Global Forest Change à l’aide des limites de Madagascar.\nMaintenant, nous allons appliquer une variante sous forme de tests logique aux communes (niveau 4 dans GADM) pour déterminer quelles communes contiennent des aires protégées.\n\n\nCode\n# Charger les données des aires protégées\nAP_Vahatra &lt;- st_read(\"data/AP_Vahatra.geojson\", quiet = TRUE) %&gt;%\n  st_make_valid()\n\n# Charger les communes\ncommunes &lt;- gadm(country = \"Madagascar\", level = 4, path = \"data\") %&gt;%\n  st_as_sf() %&gt;%\n  st_make_valid()\n\n# Filtrer les communes qui intersectent le buffer\ncommunes_avec_ap &lt;- communes %&gt;%\n  filter(lengths(st_intersects(., AP_Vahatra)) &gt; 0)\n\n# Visualiser les résultats\ntm_shape(communes_avec_ap) + \n  tm_borders() +\n  tm_shape(AP_Vahatra) + \n  tm_borders(col = \"green\")",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Données spatiales : types et importation</span>"
    ]
  },
  {
    "objectID": "04_mapme_biodiversity.html",
    "href": "04_mapme_biodiversity.html",
    "title": "4  L’outil mapme.biodiversity",
    "section": "",
    "text": "4.1 Démarche\nLe package mapme.biodiversity facilite l’analyse statistique de la biodiversité ou d’autres politiques et projets spatialisés. Il propose divers indicateurs pour évaluer la préservation de l’environnement et les activités humaines. Le package est conçu pour permettre des extensions futures grâce à des ressources et des indicateurs personnalisés.\nLe package fournit une interface unifiée pour télécharger et analyser différents jeux de données spatiales, gérant la complexité liée aux divers formats. Il simplifie l’accès aux données en interagissant avec plusieurs backends utilisés par les organisations qui distribuent ces données. Les utilisateurs peuvent contrôler l’analyse en sélectionnant les indicateurs à calculer, permettant ainsi un ajustement précis des processus.\nPour commencer, les utilisateurs saisissent un objet sf contenant uniquement des géométries de type polygone. Le package télécharge ensuite les données raster et vecteur spatiales et temporelles nécessaires correspondant à l’étendue du portefeuille. Les résultats sont ajoutés sous forme de colonnes de listes imbriquées dans l’objet portefeuille, permettant une utilisation aisée d’une large gamme d’indicateurs dans R.\nLe processus d’utilisation est le suivant :\nCode\nlibrary(DiagrammeR) # Package R pour produire des diagrammes Mermaid\n\n#| fig-cap: \"Processus de traitement avec mapme.biodiversity\"\n\nmermaid(\"\ngraph TB\n    AA(Définition des polygones d'analyse)\n    A(Définition des options)\n    B(Acquisition des ressources)\n    C(Calcul des indicateurs)\n    D(Analyse statistique avec R)\n    E(Export vers QGIS ou autre)\n    AA--&gt;A\n    A--&gt;B\n    B--&gt;C\n    C--&gt;D\n    C--&gt;E\n\")",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>L'outil mapme.biodiversity</span>"
    ]
  },
  {
    "objectID": "04_mapme_biodiversity.html#tutoriel-pratique-avec-mapme.biodiversity",
    "href": "04_mapme_biodiversity.html#tutoriel-pratique-avec-mapme.biodiversity",
    "title": "4  L’outil mapme.biodiversity",
    "section": "4.2 Tutoriel pratique avec mapme.biodiversity",
    "text": "4.2 Tutoriel pratique avec mapme.biodiversity\nNous allons maintenant découvrir comment utiliser le package mapme.biodiversity de manière pratique. Pour cela, nous allons travailler avec le jeu de données data/AP_Vahatra.geojson, qui contient des informations sur les aires protégées à Madagascar.\n\n4.2.1 Charger les données d’aires protégées\nNous allons commencer par charger notre jeu de données d’aires protégées, qui est stocké au format GeoJSON.\n\n\nCode\nlibrary(mapme.biodiversity)\nlibrary(sf)\nlibrary(tidyverse)\nlibrary(tmap)\nlibrary(progressr) # Pour avoir des bares de progression\nlibrary(tictoc) # Pour minuter des temps d'exécution\nlibrary(future) # Pour permettre du calcul parallèle\n\n# Charger le jeu de données AP_Vahatra\nAP_Vahatra &lt;- st_read(\"data/AP_Vahatra.geojson\", quiet = TRUE)\n\n\n\n\n4.2.2 Définir les options standard avec mapme_options\nAvant d’acquérir les ressources, nous devons définir certaines options pour le package, comme le répertoire de sortie.\n\n\nCode\n# Définir le répertoire de sortie\nmapme_options(outdir = \"data/mapme\")\n\n\n\n\n4.2.3 Exploration des indicateurs et des ressources disponibles\nAvant de se lancer dans l’acquisition des ressources, il est important de comprendre ce que le package peut faire. Utilisons les fonctions available_indicators() et available_resources() pour explorer les indicateurs et ressources disponibles.\n\n\nCode\n# Explorer les indicateurs disponibles\navailable_indicators()\n\n\n# A tibble: 40 × 3\n   name                          description                           resources\n   &lt;chr&gt;                         &lt;chr&gt;                                 &lt;list&gt;   \n 1 biodiversity_intactness_index Averaged biodiversity intactness ind… &lt;tibble&gt; \n 2 biome                         Areal statistics of biomes from TEOW  &lt;tibble&gt; \n 3 burned_area                   Monthly burned area detected by MODI… &lt;tibble&gt; \n 4 deforestation_drivers         Areal statistics of deforestation dr… &lt;tibble&gt; \n 5 drought_indicator             Relative wetness statistics based on… &lt;tibble&gt; \n 6 ecoregion                     Areal statstics of ecoregions based … &lt;tibble&gt; \n 7 elevation                     Statistics of elevation based on NAS… &lt;tibble&gt; \n 8 exposed_population_acled      Number of people exposed to conflict… &lt;tibble&gt; \n 9 exposed_population_ucdp       Number of people exposed to conflict… &lt;tibble&gt; \n10 fatalities_acled              Number of fatalities by event type b… &lt;tibble&gt; \n# ℹ 30 more rows\n\n\nCode\n# Explorer les ressources disponibles\navailable_resources()\n\n\n# A tibble: 35 × 5\n   name                          description                licence source type \n   &lt;chr&gt;                         &lt;chr&gt;                      &lt;chr&gt;   &lt;chr&gt;  &lt;chr&gt;\n 1 accessibility_2000            Accessibility data for th… See JR… https… rast…\n 2 acled                         Armed Conflict Location &… Visit … Visit… vect…\n 3 biodiversity_intactness_index Biodiversity Intactness I… CC-BY-… https… rast…\n 4 chelsa                        Climatologies at High res… Unknow… https… rast…\n 5 chirps                        Climate Hazards Group Inf… CC - u… https… rast…\n 6 esalandcover                  Copernicus Land Monitorin… CC-BY … https… rast…\n 7 fritz_et_al                   Drivers of deforestation … CC-BY … https… rast…\n 8 gfw_emissions                 Global Forest Watch - CO2… CC-BY … https… rast…\n 9 gfw_lossyear                  Global Forest Watch - Yea… CC-BY … https… rast…\n10 gfw_treecover                 Global Forest Watch - Per… CC-BY … https… rast…\n# ℹ 25 more rows\n\n\nCes fonctions permettent de voir la liste des indicateurs et ressources que le package propose. Vous pouvez également consulter l’aide en ligne pour chaque indicateur ou ressource afin de mieux comprendre leur utilité.\n\nExercice : Quelles ressources sont disponibles pour calculer la pente, l’altitude, la distance aux villes, le couvert forestier annuel et la densité de population ? Consultez régulièrement cette liste, car elle peut évoluer au fil des mises à jour du package.\n\n\n\n4.2.4 Acquisition des ressources nécessaires\nNous allons maintenant acquérir les ressources spatiales nécessaires pour nos analyses. Le package mapme.biodiversity propose un large éventail de ressources, notamment des données d’altitude, de couvert forestier, et de temps de déplacement jusqu’à une ville.\n\n\nCode\n# Acquérir les ressources pour l'élévation\nAP_Vahatra &lt;- get_resources(\n  x = AP_Vahatra,\n  get_nasa_srtm()\n)\n\n# Calculer l'indicateur d'élévation\n\ntic() # On lance un minuteur\nwith_progress({\n  AP_Vahatra &lt;- AP_Vahatra %&gt;%\n    calc_indicators(calc_elevation())\n})\ntoc() # On relève le minuteur, 123 secondes sur mon test\n\n\n\n\n4.2.5 Parallélisation avec {future}\nLe package mapme.biodiversity suit le paradigme de calcul parallèle du package {future}. Cela signifie que vous, en tant qu’utilisateur, pouvez décider de configurer le calcul en parallèle ou non. Depuis la version 0.9 de {mapme.biodiversity}, un pré-découpage est appliqué à tous les actifs du portefeuille, ce qui permet de diviser les actifs en composantes de taille approximativement égale. Ces composantes peuvent ensuite être itérées en parallèle afin d’accélérer le traitement. Les valeurs des indicateurs seront ensuite agrégées automatiquement.\nVoici un exemple d’utilisation de la parallélisation avec le plan cluster, qui permet de répartir les calculs sur plusieurs cœurs de votre machine :\n\n\nCode\nplan(cluster, workers = 6)\n\n# tic() # On lance un minuteur\nwith_progress({\n  AP_Vahatra &lt;- AP_Vahatra %&gt;%\n    calc_indicators(calc_elevation())\n})\n\nplan(sequential) # On libère les processus parallèles réservés\n# toc() # On relève le minuteur, 69 secondes sur mon test\n\n\n\n\n4.2.6 Acquisition des autres ressources\n\n\nCode\n# Acquérir les ressources pour la pente, le couvert forestier et le temps de déplacement\nwith_progress({\n  AP_Vahatra &lt;- AP_Vahatra %&gt;%\n    get_resources(get_gfw_treecover(),\n                  get_gfw_lossyear(),\n                  get_nelson_et_al(ranges = \"5k_110mio\")\n  )\n})\n\n\n\n\n4.2.7 Calcul des indicateurs\nAprès l’acquisition des ressources, nous allons calculer les indicateurs pour chaque polygone de notre portefeuille. Les indicateurs permettent de synthétiser les informations spatiales pour chaque entité géographique (aire protégée) de notre jeu de données.\n\n\nCode\nplan(cluster, workers = 6)\n# tic()\nwith_progress({\n  AP_Vahatra &lt;- AP_Vahatra %&gt;%\n    calc_indicators(\n      calc_slope(),\n      calc_treecover_area(years = 2000:2023, min_size = 1, min_cover = 30),\n      calc_traveltime()\n    )\n})\nplan(sequential)\n# toc() # 331 secondes\n\n\n\n\n4.2.8 Visualisation des résultats\nPour visualiser les résultats, nous allons utiliser le package tmap. Cela nous permettra de cartographier certaines des valeurs d’indicateurs calculées, telles que l’élévation moyenne ou la couverture forestière des aires protégées.\n\n\nCode\n# Visualiser les aires protégées colorées par l'élévation moyenne\ntmap_mode(\"view\")\nAP_Vahatra %&gt;%\n  portfolio_long() %&gt;%\n  filter(variable == \"elevation_mean\") %&gt;%\n  tm_shape() +\n  tm_polygons(col = \"value\", title = \"Altitude Moyenne (m)\")",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>L'outil mapme.biodiversity</span>"
    ]
  },
  {
    "objectID": "05_experimentations_aleatoires.html",
    "href": "05_experimentations_aleatoires.html",
    "title": "5  Expérimentations par assignation aléatoire",
    "section": "",
    "text": "5.1 Mise en pratique",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Expérimentations par assignation aléatoire</span>"
    ]
  },
  {
    "objectID": "05_experimentations_aleatoires.html#mise-en-pratique",
    "href": "05_experimentations_aleatoires.html#mise-en-pratique",
    "title": "5  Expérimentations par assignation aléatoire",
    "section": "",
    "text": "ATTENTION : Il va de soi que les AP malgaches n’ont à aucun moment été assignées aléatoirement. Lors de cette séquence, on fait “comme si”, pour montrer la manière dont les données sont analysées quand il y a eu assignation aléatoire. On verra en fin de session les limites d’une telle approche et dans les suivantes des manières de construire des contrefactuels plus vraisemblables pour un sujet comme celui-ci.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Expérimentations par assignation aléatoire</span>"
    ]
  },
  {
    "objectID": "05_experimentations_aleatoires.html#préparation-des-données",
    "href": "05_experimentations_aleatoires.html#préparation-des-données",
    "title": "5  Expérimentations par assignation aléatoire",
    "section": "5.2 Préparation des données",
    "text": "5.2 Préparation des données\nPour commencer, on charge les librairies requises (après les avoir installées si nécessaire).\n\n\nCode\n# On charge les librairies utiles pour cette analyse\nlibrary(tidyverse) # Facilite la manipulation de données\nlibrary(gt) # Aide à formater de jolis tableaux de rendu\nlibrary(broom) # Aide à formater les rendus de régressions\nlibrary(stargazer) # idem\nlibrary(sf) # Pour les données spatiales\nlibrary(lubridate) # Pour gérer des dates\nlibrary(htmltools)\nlibrary(mapme.biodiversity)\nlibrary(units)\n\n# Désactiver les notations scientifiques\noptions(scipen = 999)\n\n# On charge AP_Vahatra\nAP_Vahatra &lt;- read_rds(\"data/AP_Vahatra_mapme.rds\")",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Expérimentations par assignation aléatoire</span>"
    ]
  },
  {
    "objectID": "05_experimentations_aleatoires.html#analyse-des-équilibres-initiaux",
    "href": "05_experimentations_aleatoires.html#analyse-des-équilibres-initiaux",
    "title": "5  Expérimentations par assignation aléatoire",
    "section": "5.3 Analyse des équilibres initiaux",
    "text": "5.3 Analyse des équilibres initiaux\nOn commence par vérifier s’il existe des déséquilibres flagrants entre les aires qui ont été protégées avant 2015 et celles qui ont été protégées en 2015, en matière de surface totale ou de part couverte par des forêts en 2000.\n\n\nCode\nlibrary(units)\n\n# Correctly define variables with units\nAP_RCT &lt;- AP_Vahatra %&gt;%\n  portfolio_wide() %&gt;% \n  mutate(Groupe = ifelse(year(date_creation) &lt; 2015, \"Traitement\", \"Contrôle\"),\n         `Couvert forestier en 2000` = `treecover_area_2000-01-01_treecover_ha`,\n         `Surface (ha)` = as.numeric(st_area(AP_Vahatra)) / 10000,\n         `Couvert forestier en 2000 (%)` = `Couvert forestier en 2000` / `Surface (ha)`)\n\n# On fait une série de tests de comparaison de moyenne\nt_tests &lt;- AP_RCT %&gt;%\n  st_drop_geometry() %&gt;%\n  summarise(across(`Surface (ha)`:`Couvert forestier en 2000 (%)`,\n                   ~ t.test(.[Groupe == \"Contrôle\"], .[Groupe == \"Traitement\"])$p.value)) %&gt;%\n  mutate(Groupe = \"t-test\")\n\nequilibre_avant &lt;- AP_RCT %&gt;%\n  st_drop_geometry() %&gt;%\n  group_by(Groupe) %&gt;%\n  summarise(`Nombre d'aires` = n(),\n            `Surface (ha)` = mean(`Surface (ha)`),\n            `Couvert forestier en 2000 (%)` = mean(`Couvert forestier en 2000 (%)`, na.rm = TRUE)) %&gt;%\n  bind_rows(t_tests) %&gt;%\n  mutate(across(!Groupe, ~round(., 2)))\n\n# Ce qui suit est une série d'opérations pour formater le rendu en tableau\nequilibre_avant %&gt;%\n  t() %&gt;%\n  as.data.frame() %&gt;%\n  tibble::rownames_to_column() %&gt;%\n  `colnames&lt;-` (filter(., row_number() == 1)) %&gt;%\n  filter(row_number() != 1) %&gt;%\n  gt() %&gt;%\n  tab_header(title = \"Équilibre des variables avant intervention\",\n             subtitle = \"(exercice : \\\"comme si\\\" c'était une RCT)\") %&gt;%\n  tab_source_note(\"Source : Association Vahatra et données GFC\")\n\n\n\n\n\n\n\n\nÉquilibre des variables avant intervention\n\n\n(exercice : \"comme si\" c'était une RCT)\n\n\nGroupe\nContrôle\nTraitement\nt-test\n\n\n\n\nNombre d'aires\n53\n45\nNA\n\n\nSurface (ha)\n66539.77\n63728.00\n0.88\n\n\nCouvert forestier en 2000 (%)\n0.62\n0.72\n0.14\n\n\n\nSource : Association Vahatra et données GFC\n\n\n\n\n\n\n\n\n\nExercice : Analysez le résultat de cette table.\n\nEn moyenne, les deux groupes sont assez proches en termes de surface et de couvert forestier, et le test de Student ne permet pas de rejeter l’hypothèse nulle concernant une différence de moyenne sur ces critères.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Expérimentations par assignation aléatoire</span>"
    ]
  },
  {
    "objectID": "05_experimentations_aleatoires.html#différences-de-déforestation-après-intervention",
    "href": "05_experimentations_aleatoires.html#différences-de-déforestation-après-intervention",
    "title": "5  Expérimentations par assignation aléatoire",
    "section": "5.4 Différences de déforestation “après intervention”",
    "text": "5.4 Différences de déforestation “après intervention”\nOn va maintenant s’intéresser aux différences de déforestation observées “après intervention” dans le groupe de traitement, entre 2000 et 2014.\n\n\nCode\n# Calculer le taux annuel de déforestation moyen pour la période 2000-2014\n\nAP_RCT &lt;- AP_RCT %&gt;%\n  mutate(taux_deforestation_2000_2014 = \n           -((`treecover_area_2014-01-01_treecover_ha` / \n              `treecover_area_2000-01-01_treecover_ha`)^(1/14) - 1) * 100)\n\n# Comparer les taux de déforestation moyens entre les groupes\ncomparaison_deforestation &lt;- AP_RCT %&gt;%\n  st_drop_geometry() %&gt;%\n  group_by(Groupe) %&gt;%\n  summarise(`Taux annuel de déforestation moyen 2000-2014 (%)` = \n              mean(taux_deforestation_2000_2014, na.rm = TRUE)) %&gt;%\n  mutate(across(!Groupe, ~round(., 2)))\n\n# Ce qui suit est une série d'opérations pour formater le rendu en tableau\ncomparaison_deforestation %&gt;%\n  t() %&gt;%\n  as.data.frame() %&gt;%\n  tibble::rownames_to_column() %&gt;%\n  `colnames&lt;-` (filter(., row_number() == 1)) %&gt;%\n  filter(row_number() != 1) %&gt;%\n  gt() %&gt;%\n  tab_header(title = \"Moyennes des taux annuels de déforestation\",\n             subtitle = \"(exercice : \\\"comme si\\\" c'était une RCT)\") %&gt;%\n  tab_source_note(\"Source : Association Vahatra et données GFC\")\n\n\n\n\n\n\n\n\nMoyennes des taux annuels de déforestation\n\n\n(exercice : \"comme si\" c'était une RCT)\n\n\nGroupe\nContrôle\nTraitement\n\n\n\n\nTaux annuel de déforestation moyen 2000-2014 (%)\n0.70\n0.35\n\n\n\nSource : Association Vahatra et données GFC\n\n\n\n\n\n\n\n\n\nExercice : Commentez le résultat de cette table.\n\nOn peut également réaliser une régression simple, qu’on présente selon le format courant pour la littérature en économie grâce au package {stargazer} (Hlavac 2022).\n\n\nCode\n# On exécute une régression pour la période 2000-2014\ndef_2000_2014 &lt;- lm(taux_deforestation_2000_2014 ~ Groupe, data = AP_RCT)\n\n# On consolide les résultats des régressions dans une table qu'on formate\n# avec le package stargazer\nrct_out1 &lt;- stargazer(def_2000_2014, type = \"html\",\n          title = \"Impact de la conservation sur la perte de couvert forestier\",\n          notes = \"Données : Association Vahatra et données GFC\")  \n\n\n\n\n\n\nImpact de la conservation sur la perte de couvert forestier\n\n\n\n\n\n\nDependent variable:\n\n\n\n\n\n\n\ntaux_deforestation_2000_2014\n\n\n\n\n\nGroupeTraitement\n-0.349**\n\n\n\n(0.152)\n\n\n\n\n\n\nConstant\n0.699***\n\n\n\n(0.103)\n\n\n\n\n\n\n\n\n\nObservations\n97\n\n\nR2\n0.052\n\n\nAdjusted R2\n0.042\n\n\nResidual Std. Error\n0.747 (df = 95)\n\n\nF Statistic\n5.255** (df = 1; 95)\n\n\n\n\n\nNote:\n*p&lt;0.1; **p&lt;0.05; ***p&lt;0.01\n\n\n\nDonnées : Association Vahatra et données GFC\n\n\n\n\n\n\n\nExercice : Analysez le résultat de cette table. Qu’est-ce qu’elle suggère ?",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Expérimentations par assignation aléatoire</span>"
    ]
  },
  {
    "objectID": "05_experimentations_aleatoires.html#analyse-des-variables-topologiques-et-de-laccessibilité",
    "href": "05_experimentations_aleatoires.html#analyse-des-variables-topologiques-et-de-laccessibilité",
    "title": "5  Expérimentations par assignation aléatoire",
    "section": "5.5 Analyse des variables topologiques et de l’accessibilité",
    "text": "5.5 Analyse des variables topologiques et de l’accessibilité\nOn analyse ensuite la relation aux variables topologiques (altitude, pente) et de temps de trajet à la ville la plus proche en 2015. Le seuil retenu ici pour considérer une localité comme une ville est qu’elle ait au moins 5000 habitants.\n\n\nCode\n# On fait une série de tests de comparaison de moyenne pour les variables topologiques\n\nt_tests_topo &lt;- AP_RCT %&gt;% \n  st_drop_geometry() %&gt;%\n  summarise(across(c(`elevation_2000-02-01_elevation_mean_m`, \n                   `slope_2000-02-01_slope_mean_degrees`, \n                   `traveltime_2015-01-01_5k_110mio_traveltime_mean_minutes`),\n                   ~ t.test(as.numeric(.[Groupe == \"Contrôle\"]), as.numeric(.[Groupe == \"Traitement\"]))$p.value)) %&gt;% \n  rename(`Altitude moyenne (m)` = `elevation_2000-02-01_elevation_mean_m`,\n         `Pente moyenne (degrés)` = `slope_2000-02-01_slope_mean_degrees`,\n         `Temps de trajet moyen (minutes)` = \n           `traveltime_2015-01-01_5k_110mio_traveltime_mean_minutes`) %&gt;%\n  mutate(Groupe = \"t-test\")\n\nequilibre_topo &lt;- AP_RCT %&gt;%\n  st_drop_geometry() %&gt;%\n  group_by(Groupe) %&gt;%\n  summarise(`Nombre d'aires` = n(),\n            `Altitude moyenne (m)` = mean(`elevation_2000-02-01_elevation_mean_m`, na.rm = TRUE),\n            `Pente moyenne (degrés)` = mean(`slope_2000-02-01_slope_mean_degrees`, na.rm = TRUE),\n            `Temps de trajet moyen (minutes)` = mean(`traveltime_2015-01-01_5k_110mio_traveltime_mean_minutes`, na.rm = TRUE)) %&gt;%\n  bind_rows(t_tests_topo) %&gt;% \n  mutate(across(!Groupe, ~round(., 2)))\n\n# Ce qui suit est une série d'opérations pour formater le rendu en tableau\nequilibre_topo %&gt;%\n  t() %&gt;%\n  as.data.frame() %&gt;%\n  tibble::rownames_to_column() %&gt;%\n  `colnames&lt;-` (filter(., row_number() == 1)) %&gt;%\n  filter(row_number() != 1) %&gt;%\n  gt() %&gt;%\n  tab_header(title = \"Équilibre entre les groupes en matière topologique\",\n             subtitle = \"(exercice : \\\"comme si\\\" c'était une RCT)\") %&gt;%\n  tab_source_note(\"Source : Nasa SRTM, Nelson et al.\")\n\n\n\n\n\n\n\n\nÉquilibre entre les groupes en matière topologique\n\n\n(exercice : \"comme si\" c'était une RCT)\n\n\nGroupe\nContrôle\nTraitement\nt-test\n\n\n\n\nNombre d'aires\n53\n45\nNA\n\n\nAltitude moyenne (m)\n518.99\n578.90\n0.58\n\n\nPente moyenne (degrés)\n9.59\n10.93\n0.31\n\n\nTemps de trajet moyen (minutes)\n147.08\n255.12\n0.01\n\n\n\nSource : Nasa SRTM, Nelson et al.\n\n\n\n\n\n\n\n\nLe temps de trajet aux villes est significativement distinct entre les deux groupes.\nOn essaye de limiter ce biais en ajoutant le temps de trajet à une ville comme variable de contrôle à notre régression.\n\n\nCode\nAP_RCT2 &lt;- AP_RCT %&gt;%\n  rename(`Temps de trajet moyen (minutes)` = \n           `traveltime_2015-01-01_5k_110mio_traveltime_mean_minutes`)\n\n# On exécute une régression pour la période 2000-2014\ndef_2000_2014 &lt;- lm(taux_deforestation_2000_2014 ~ \n                      Groupe + `Temps de trajet moyen (minutes)`,\n                    data = AP_RCT2)\n\n# On consolide les résultats des régressions dans une table qu'on formate\n# avec le package stargazer\nrct_out2 &lt;- stargazer(def_2000_2014, type = \"html\",\n          title = \"Impact de la conservation sur la perte de couvert forestier (en contrôlant pour l'accessibilité)\",\n          notes = \"Données : Association Vahatra et données GFC\")  \n\n\n\n\n\n\nImpact de la conservation sur la perte de couvert forestier (en contrôlant pour l'accessibilité)\n\n\n\n\n\n\nDependent variable:\n\n\n\n\n\n\n\ntaux_deforestation_2000_2014\n\n\n\n\n\nGroupeTraitement\n-0.299*\n\n\n\n(0.160)\n\n\n\n\n\n\n`Temps de trajet moyen (minutes)`\n-0.0004\n\n\n\n(0.0004)\n\n\n\n\n\n\nConstant\n0.764***\n\n\n\n(0.121)\n\n\n\n\n\n\n\n\n\nObservations\n97\n\n\nR2\n0.063\n\n\nAdjusted R2\n0.043\n\n\nResidual Std. Error\n0.747 (df = 94)\n\n\nF Statistic\n3.148** (df = 2; 94)\n\n\n\n\n\nNote:\n*p&lt;0.1; **p&lt;0.05; ***p&lt;0.01\n\n\n\nDonnées : Association Vahatra et données GFC\n\n\n\n\n\n\n\nExercice : interprétez le résultat\n\n\n\n\n\nHlavac, Marek. 2022. Stargazer: Well-Formatted Regression and Summary Statistics Tables. https://CRAN.R-project.org/package=stargazer.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Expérimentations par assignation aléatoire</span>"
    ]
  },
  {
    "objectID": "06_avant_apres.html",
    "href": "06_avant_apres.html",
    "title": "6  Comparaisons avant-après",
    "section": "",
    "text": "7 Comparaison avant-après\nL’intuition initiale de cette stratégie est que le meilleur contrefactuel de l’AP est elle-même avant la mise en place du statut.\nAinsi, nous allons comparer pour chaque AP, les taux de déforestation entre les années qui précèdent la création de l’AP et les années qui suivent la création.\nEn revanche, comme vu dans la partie théorique, cette approche repose sur l’hypothèse que la seule différence entre les périodes est la mise en place de la politique.\nAutrement dit, le seul facteur entre ces différentes périodes qui impactent le taux de dégradation des forêts est la mise en place de l’AP.\nCi-dessous, un tableau représentant les dates de création des aires protégées.\n\n\nCode\nlibrary(tidyverse)\nlibrary(lubridate)\nlibrary(sf)\nlibrary(gt)\nlibrary(mapme.biodiversity)\n\n# Désactiver les notations scientifiques\noptions(scipen =999)\n\n\n# On reprend les données telles que préparées au chapitre 3\nAP_Vahatra &lt;- read_rds(\"data/AP_Vahatra_mapme.rds\")\n\nfocus_stats &lt;- AP_Vahatra %&gt;%\n  filter(an_creation &gt; 2000 & an_creation &lt; 2023) %&gt;%\n  st_drop_geometry() %&gt;%\n  summarise(n = n(),\n            an_min = min(an_creation),\n            an_max = max(an_creation))\n\nAP_Vahatra %&gt;%\n  mutate(an_creation = year(date_creation)) %&gt;%\n  select(nom, an_creation) %&gt;%\n  ggplot(aes(x = an_creation)) +\n  geom_rect(xmin = focus_stats$an_min, xmax = focus_stats$an_max, ymin = 0, \n            ymax = 54, fill = \"yellow\", alpha = 0.3) +\n  geom_bar() +\n  xlim(c(NA, 2024)) + \n  geom_vline(xintercept = c(2000, 2023), col = \"red\", show.legend = TRUE) +\n  ylim(NA, 53) +\n  xlab(\"Année de création\") +\n  ylab(\"Nombre d'aires protégées\") +\n  ggtitle(\"Dates de création des AP et de disponibilité\\ndes données GFC\")\n\n\n\n\n\n\n\n\n\nLes données mobilisées sont celles de Global Forest Cover (GFC) pour lesquelles on dispose d’un historique allant de 2000 à 2023. On se concentre sur les aires protégées dont le statut a été décrété entre ces deux dates.\nNotre échantillon final contient 61 AP (sur les 98 initiales de la base de données Vahatra _ en jaune sur le graphique).\nNous normalisons les dates d’octroi du statut d’AP c’est à dire qu’on transforme les années calendaires (2002, 2003,…) en année relative à la mise en place de l’AP.\nPar exemple, si une AP est créée en 2015 (qui correspondra à l’année 0), toutes les autres années seront exprimées relativement à celle-ci et donc, 2010 sera égale à -5 et 2020 à 5.\nCette transformation nous permet de pouvoir visualiser les données. Dans le tableau suivant, nous avons la moyenne annuelle de la surface (exprimée en hectare et en pourcentage) de l’AP qui a été déforestée pendant les année précédant et celles suivant la création de l’AP.\n\n\nCode\nsequence_AP &lt;- AP_Vahatra %&gt;%\n  filter(an_creation &gt; 2000 & an_creation &lt; 2023) %&gt;%\n  portfolio_long() %&gt;%\n  filter(variable == \"treecover\") %&gt;%\n  mutate(an_valeur = year(datetime), \n         tx_defor = ifelse(nom != lag(nom), NA, \n                           -((value - lag(value)) / lag(value))),\n         an_val_crea = an_valeur - an_creation,\n         sequence_crea = ifelse(an_val_crea &lt; 0, \"Avant création\",\n                                ifelse(an_val_crea &gt; 0, \"Après création\", \n                                       \"Année de création\")),\n         sequence_crea = factor(sequence_crea, levels = c(\"Avant création\", \n                                                         \"Année de création\",\n                                                         \"Après création\")))\n\nmoy_defor &lt;- sequence_AP %&gt;%\n  st_drop_geometry() %&gt;%\n  group_by(sequence_crea) %&gt;%\n  summarise(`Déforestation annuelle moyenne` = mean(tx_defor, na.rm = TRUE))\n\ngt(moy_defor) %&gt;% \n  fmt_percent(columns = `Déforestation annuelle moyenne`) %&gt;%\n  tab_header(title = \"Déforestation avant et après création de l'AP\")  %&gt;% \n  cols_label(sequence_crea = \" \") %&gt;%\n  tab_source_note(c(\"Source : GFC et association Vahatra.\",\n                    \"Calculs des auteurs.\"))\n\n\n\n\n\n\n\n\nDéforestation avant et après création de l'AP\n\n\n\nDéforestation annuelle moyenne\n\n\n\n\nAvant création\n0.67%\n\n\nAnnée de création\n1.09%\n\n\nAprès création\n1.26%\n\n\n\nSource : GFC et association Vahatra.\n\n\nCalculs des auteurs.\n\n\n\n\n\n\n\n\nD’après le tableau ci-dessus, quelles conclusions pouvons-nous tirer ?\nVoici une vue des valeurs 0 chaque année.\n\n\nCode\nsequence_AP %&gt;%\n  st_drop_geometry() %&gt;%\n  filter(an_val_crea &gt; -5 & an_val_crea &lt; 5) %&gt;%\n  group_by(an_val_crea) %&gt;%\n  summarise(defor_moy = mean(tx_defor, na.rm = TRUE)) %&gt;%\n  ggplot(aes(x = an_val_crea, y = defor_moy)) +\n  geom_point() +\n  geom_vline(xintercept = 0, col = \"blue\") +\n  scale_y_continuous(labels = scales::label_percent()) +\n  xlab(\"Avant création &gt; Année de création &gt; Après création\") +\n  ylab(\"Taux moyen de déforestation\")\n\n\n\n\n\n\n\n\n\n\nExercice: Quelles analyses pourraient être menées pour compléter ces premiers résultats ?",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Comparaisons avant-après</span>"
    ]
  },
  {
    "objectID": "08_appariement.html",
    "href": "08_appariement.html",
    "title": "8  Méthodes d’appariement",
    "section": "",
    "text": "8.1 La question de la comparabilité des groupes\nOn a vu dans le chapitre précédent que les comparaisons simples réalisées entre les premières et les dernières aires à avoir été formellement protégées pose problème.\nOn va maintenant chercher à renforcer la comparabilité entre le groupe de traitement et le groupe de contrôle en réalisant un appariemment (cf. diapos de présentation).\nOn va utiliser le package {MatchIt} : ne pas hésiter à se référer à la documentation du package.\nOn va commencer par réaliser quelques ajustements, car {MatchIt} requiert qu’aucune valeur des variables mobilisées ne soit manquante. On va donc retirer les observations comportant des NA.\nCode\nlibrary(tidyverse) # Simplifie la manipulation de données\nlibrary(lubridate) # Simplifie les opérations sur des dates\nlibrary(sf) # Pour traiter les données spatiales\nlibrary(MatchIt) # Pour réaliser les appariements.\nlibrary(cobalt) # Pour les tests d'équilibre sur l'appariement\nlibrary(gt) # Pour faire de jolies tables\nlibrary(stargazer) # Pour présenter les résultats de régressions\nlibrary(mapme.biodiversity)\nlibrary(htmltools)\n\n# Désactiver les notations scientifiques\noptions(scipen = 999)\n\n# Charger les données\nAP_Vahatra &lt;- read_rds(\"data/AP_Vahatra_mapme.rds\") %&gt;%\n  portfolio_wide() %&gt;%\n  mutate(Groupe = ifelse(year(date_creation) &lt; 2015, \"Traitement\", \"Contrôle\"))\n\n# Préparer les données sans valeurs manquantes\nVahatra_defor_noNA &lt;- AP_Vahatra %&gt;%\n  mutate(surface_ha = as.numeric(st_area(AP_Vahatra)) / 10000, \n         couv_foret_2000 = `treecover_area_2000-01-01_treecover_ha` / surface_ha * 100,\n         altitude = `elevation_2000-02-01_elevation_mean_m`,\n         pente = `slope_2000-02-01_slope_mean_degrees`,\n         dist_ville = `traveltime_2015-01-01_5k_110mio_traveltime_mean_minutes`,\n         traitement = ifelse(year(date_creation) &lt; 2015, 1, 0),\n         taux_deforestation_2000_2014 = \n           -((`treecover_area_2014-01-01_treecover_ha` / \n              `treecover_area_2000-01-01_treecover_ha`)^(1/14) - 1) * 100) %&gt;%\n  filter(!is.na(couv_foret_2000), !is.na(dist_ville), !is.na(altitude), !is.na(pente))\n\nsummary(Vahatra_defor_noNA)\n\nVahatra_defor_noNA %&gt;%\n  st_drop_geometry() %&gt;%\n  group_by(Groupe, traitement) %&gt;%\n  summarise(effectif = n())\nCode\nVahatra_defor_noNA %&gt;%\n  st_drop_geometry() %&gt;%\n  group_by(Groupe) %&gt;%\n  summarize(`Nombre d'aires protégées` = n()) %&gt;%\n  gt() %&gt;%\n  tab_header(\"Observations par groupe avant appariemment\") %&gt;%\n  tab_source_note(\"Source : Association Vahatra et données GFC\")\n\n\n\n\n\n\n\n\nObservations par groupe avant appariemment\n\n\nGroupe\nNombre d'aires protégées\n\n\n\n\nContrôle\n53\n\n\nTraitement\n44\n\n\n\nSource : Association Vahatra et données GFC",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Méthodes d'appariement</span>"
    ]
  },
  {
    "objectID": "08_appariement.html#mesure-de-la-propension",
    "href": "08_appariement.html#mesure-de-la-propension",
    "title": "8  Méthodes d’appariement",
    "section": "8.2 Mesure de la propension",
    "text": "8.2 Mesure de la propension\nPour commencer, nous allons spécifier le modèle probit qui estime dans quelle mesure la propension pour une aire d’avoir été protégée avant 2015 dépend de sa taille, de son taux de couverture forestière en 2000, de son altitude, de son caractère accidenté et de sa distance d’une ville d’au moins 5000 habitants.\nCette spécification peut se représenter selon l’équation suivante qui représente un modèle probit. Un modèle probit, tout comme le logit, est un modèle de choix binaire.\n\n\nCode\n# Spécification du modèle probit\npscor &lt;- traitement ~  surface_ha + \n                       couv_foret_2000 + \n                       altitude +\n                       pente + \n                       dist_ville\n\n\nOn va maintenant réaliser une régression pour connaître l’influence de ces facteurs dans la désignation des aires comme protégées.\n\n\nCode\n# Régression probit\nreg_select &lt;- glm(formula = pscor,\n                  family = binomial(link = \"probit\"),\n                  data = Vahatra_defor_noNA)\n\nmatch_out1 &lt;- stargazer(reg_select, type = \"html\") \n\n\n\n\n\n\n\n\n\n\n\n\nDependent variable:\n\n\n\n\n\n\n\ntraitement\n\n\n\n\n\nsurface_ha\n-0.00000\n\n\n\n(0.00000)\n\n\n\n\n\n\ncouv_foret_2000\n0.001\n\n\n\n(0.005)\n\n\n\n\n\n\naltitude\n-0.0004\n\n\n\n(0.0004)\n\n\n\n\n\n\npente\n0.005\n\n\n\n(0.030)\n\n\n\n\n\n\ndist_ville\n0.003***\n\n\n\n(0.001)\n\n\n\n\n\n\nConstant\n-0.547\n\n\n\n(0.343)\n\n\n\n\n\n\n\n\n\nObservations\n97\n\n\nLog Likelihood\n-60.920\n\n\nAkaike Inf. Crit.\n133.839\n\n\n\n\n\nNote:\n*p&lt;0.1; **p&lt;0.05; ***p&lt;0.01\n\n\n\n\n\n\n\nExercice : analysez ce résultat. Quels facteurs sont corrélés avec la désignation précoce comme aire protégée ?",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Méthodes d'appariement</span>"
    ]
  },
  {
    "objectID": "08_appariement.html#appariement-sur-score-de-propension",
    "href": "08_appariement.html#appariement-sur-score-de-propension",
    "title": "8  Méthodes d’appariement",
    "section": "8.3 Appariement sur score de propension",
    "text": "8.3 Appariement sur score de propension\nOn va maintenant utiliser ce modèle pour comparer les aires protégées traitées en premier par rapport à celles traitées plus récemment.\n\n\nCode\n# Calcul du matching\ndef_00_14_match &lt;- matchit(formula = pscor,\n                           family = binomial(link = \"probit\"),\n                           method = \"nearest\",\n                           discard = \"both\",\n                           replace = FALSE,\n                           distance = \"glm\",\n                           data = Vahatra_defor_noNA)\n\nprint(def_00_14_match)\n\n\nA matchit object\n - method: 1:1 nearest neighbor matching without replacement\n - distance: Propensity score [common support]\n             - estimated with logistic regression\n - common support: units from both groups dropped\n - number of obs.: 97 (original), 78 (matched)\n - target estimand: ATT\n - covariates: surface_ha, couv_foret_2000, altitude, pente, dist_ville\n\n\nOn peut maintenant observer les équilibres entre les groupes traités et contrôle avant et après l’appariement.\n\n\nCode\nsummary(def_00_14_match)\n\n\n\nCall:\nmatchit(formula = pscor, data = Vahatra_defor_noNA, method = \"nearest\", \n    distance = \"glm\", discard = \"both\", replace = FALSE, family = binomial(link = \"probit\"))\n\nSummary of Balance for All Data:\n                Means Treated Means Control Std. Mean Diff. Var. Ratio\ndistance               0.5143        0.4032          0.5970     1.9343\nsurface_ha         65093.8897    66539.7728         -0.0184     0.5595\ncouv_foret_2000       71.9537       62.1290          0.3384     0.6778\naltitude             589.4707      518.9928          0.1459     0.6982\npente                 11.0161        9.5870          0.2145     1.0678\ndist_ville           260.4379      147.0780          0.5255     2.4284\n                eCDF Mean eCDF Max\ndistance           0.1840   0.3049\nsurface_ha         0.0993   0.2517\ncouv_foret_2000    0.0915   0.2333\naltitude           0.0943   0.2294\npente              0.0729   0.1758\ndist_ville         0.1822   0.3263\n\nSummary of Balance for Matched Data:\n                Means Treated Means Control Std. Mean Diff. Var. Ratio\ndistance               0.4666        0.4483          0.0983     1.1599\nsurface_ha         67525.2840    53400.1694          0.1799     0.9542\ncouv_foret_2000       70.1568       72.2206         -0.0711     0.8134\naltitude             563.7866      449.9603          0.2356     0.9791\npente                 10.6267        9.8470          0.1171     1.0674\ndist_ville           204.5025      168.8781          0.1651     0.9053\n                eCDF Mean eCDF Max Std. Pair Dist.\ndistance           0.0404   0.1795          0.1149\nsurface_ha         0.1049   0.2564          1.0223\ncouv_foret_2000    0.0634   0.2051          0.8333\naltitude           0.0843   0.2308          1.0357\npente              0.0550   0.1538          1.0324\ndist_ville         0.0941   0.2308          0.3906\n\nSample Sizes:\n          Control Treated\nAll            53      44\nMatched        39      39\nUnmatched       9       0\nDiscarded       5       5\n\n\n\nExercice : Étudiez les tables ci-dessus. Quel effet a eu l’appariement sur l’équilibre des variables entre le groupe de traitement et le groupe de contrôle ? Combien d’observations ont été écartées ?\n\nOn peut observer la distance entre groupe de traitement et de contrôle.\n\n\nCode\nplot(def_00_14_match, type = \"jitter\", interactive = FALSE)\n\n\n\n\n\n\n\n\n\nOn peut également représenter l’équilibre entre les variables avant et après traitement avec les graphiques suivants.\n\n\nCode\nbal.plot(def_00_14_match, var.name = \"dist_ville\", which = \"both\")\n\n\n\n\n\n\n\n\n\n\nExercice : Quel effet a eu l’appariement sur la variable de distance à la ville ? Les autres variables d’appariement produisent-elles un effet aussi visible ?",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Méthodes d'appariement</span>"
    ]
  },
  {
    "objectID": "08_appariement.html#estimation-du-résultat-en-contrôlant-pour-les-variables-dappariement",
    "href": "08_appariement.html#estimation-du-résultat-en-contrôlant-pour-les-variables-dappariement",
    "title": "8  Méthodes d’appariement",
    "section": "8.4 Estimation du résultat en contrôlant pour les variables d’appariement",
    "text": "8.4 Estimation du résultat en contrôlant pour les variables d’appariement\nLe modèle qu’on utilise pour estimer l’impact est très proche de celui exposé ci-dessus, à la différence que la variable de traitement passe dans la partie droite, et qu’elle est remplacée par la déforestation.\n\n\nCode\n# Spécification du modèle pour l'impact\nestimp &lt;- taux_deforestation_2000_2014 ~   \n                          traitement +\n                          surface_ha + \n                          couv_foret_2000 + \n                          altitude +\n                          pente + \n                          dist_ville\n\n\nOn va donc réaliser une régression, en tenant compte des pondérations générées par l’algorithme d’appariement (variable “weight”).\n\n\nCode\n# On extrait les données de l'appariement\ndef_00_14_match_data &lt;- match.data(def_00_14_match)\n\n# Régression avec pondérations\ndef_00_14_match_est &lt;- lm(formula = estimp,\n                          data = def_00_14_match_data,\n                          weights = weights)\n\n# Présentation des résultats\nmatch_out2 &lt;- stargazer(def_00_14_match_est, type = \"html\")\n\n\n\n\n\n\n\n\n\n\n\n\nDependent variable:\n\n\n\n\n\n\n\ntaux_deforestation_2000_2014\n\n\n\n\n\ntraitement\n-0.278*\n\n\n\n(0.158)\n\n\n\n\n\n\nsurface_ha\n0.00000***\n\n\n\n(0.00000)\n\n\n\n\n\n\ncouv_foret_2000\n-0.001\n\n\n\n(0.003)\n\n\n\n\n\n\naltitude\n0.0001\n\n\n\n(0.0002)\n\n\n\n\n\n\npente\n-0.009\n\n\n\n(0.017)\n\n\n\n\n\n\ndist_ville\n-0.001\n\n\n\n(0.001)\n\n\n\n\n\n\nConstant\n0.795***\n\n\n\n(0.228)\n\n\n\n\n\n\n\n\n\nObservations\n78\n\n\nR2\n0.156\n\n\nAdjusted R2\n0.084\n\n\nResidual Std. Error\n0.689 (df = 71)\n\n\nF Statistic\n2.184* (df = 6; 71)\n\n\n\n\n\nNote:\n*p&lt;0.1; **p&lt;0.05; ***p&lt;0.01",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Méthodes d'appariement</span>"
    ]
  },
  {
    "objectID": "08_appariement.html#exercices",
    "href": "08_appariement.html#exercices",
    "title": "8  Méthodes d’appariement",
    "section": "8.5 Exercices",
    "text": "8.5 Exercices\n\n8.5.1 Exercice simple\nAnalysez, interprétez et critiquez les résultats ci-dessus.\n\n\n8.5.2 Exercice intermédiaire\nAjoutez des variables d’intérêt et modifiez les paramètres de la fonction de matching.\n\n\n8.5.3 Exercice avancé\nRéalisez une analyse analogue avec les données de feux. Rédigez une analyse interprétative.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Méthodes d'appariement</span>"
    ]
  },
  {
    "objectID": "10_synthese.html",
    "href": "10_synthese.html",
    "title": "10  Synthèse",
    "section": "",
    "text": "D’autres méthodes quantitatives existent : RDD, synthetic controls.\nEnjeux de croisement des méthodes.",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Synthèse</span>"
    ]
  },
  {
    "objectID": "11_references.html",
    "href": "11_references.html",
    "title": "Bibliographie",
    "section": "",
    "text": "Barnier, Julien. 2022. “Introduction à R Et Au\nTidyverse.” https://juba.github.io/tidyverse/index.html.\n\n\nDevenish, Katie, Sébastien Desbureaux, Simon Willcock, and Julia P. G.\nJones. 2022. “On Track to Achieve No Net Loss of Forest at\nMadagascar’s Biggest Mine.” Nature\nSustainability 5 (6): 498–508. https://doi.org/10.1038/s41893-022-00850-7.\n\n\nGaliana, Lino, and Olivier Meslin, eds. 2022. “utilitR:\nDocumentation Collaborative Sur r.” https://www.book.utilitr.org/.\n\n\nGörgen, Darius A., and Om Prakash Bhandari. 2022.\nMapme.biodiversity: Efficient Monitoring of Global Biodiversity\nPortfolios. https://CRAN.R-project.org/package=mapme.biodiversity.\n\n\nGrolemund, Garrett, and Hadley Wickham. 2022. R for Data Science:\nImport, Tidy, Transform, Visualize, and Model Data. 1st edition.\nSebastopol, CA: O’Reilly Media. https://r4ds.had.co.nz/.\n\n\nHlavac, Marek. 2022. Stargazer: Well-Formatted Regression and\nSummary Statistics Tables. https://CRAN.R-project.org/package=stargazer.\n\n\nLarmarange, Joseph. 2024. Guide-r : Guide Pour l’analyse de Données\nd’enquêtes Avec r. https://larmarange.github.io/guide-R/.\n\n\nLovelace, Robin, Jakub Nowosad, and Jannes Muenchow. 2022.\nGeocomputation with R. Boca Raton London New York: Routledge.\nhttps://geocompr.robinlovelace.net/.\n\n\nWolf, Christopher, Taal Levi, William J. Ripple, Diego A.\nZárrate-Charry, and Matthew G. Betts. 2021. “A Forest Loss Report\nCard for the World’s Protected Areas.” Nature Ecology &\nEvolution 5 (4): 520–29. https://doi.org/10.1038/s41559-021-01389-0.",
    "crumbs": [
      "Bibliographie"
    ]
  },
  {
    "objectID": "07_unites_analyse.html",
    "href": "07_unites_analyse.html",
    "title": "7  Clarification sur les unités d’analyse",
    "section": "",
    "text": "7.1 Quelles unités d’analyse\nOn souhaite définir une stratégie empirique pour évaluer une politique publique avec des méthodes quantitatives, trois choix principaux doivent être définis :\nOn se focalise souvent sur les questions 2. et 3, mais la question 1. est souvent considérée comme évidente. Cette question 1. suscite pourtant beaucoup de confusion quand on apprend l’économétrie.\nNous allons illuster cette question avec le cas de la conservation. Typiquement, les évaluations de l’impact des politiques de conservation prennent habituellement comme référence (comme ligne du tableau) :\nUne approche courante consiste à diviser le territoires en mailles, carrées ou en forme d’alvéoles d’abeilles (hexagones), et à calculer des indicateurs pour chacune de ces mailles.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Clarification sur les unités d'analyse</span>"
    ]
  },
  {
    "objectID": "07_unites_analyse.html#quelles-unités-danalyse",
    "href": "07_unites_analyse.html#quelles-unités-danalyse",
    "title": "7  Clarification sur les unités d’analyse",
    "section": "",
    "text": "Quel types d’unités allons-nous comparer ? (Quelles lignes dans mon tableau ?)\nQuelles variables prendre en compte ? (Quelles colonnes dans mon tableau ?)\nComment constituer une comparaison crédible ? (Quelle méthode d’analyse et quelles spécifications ?)\n\n\n\n\nDes pays, pour voir comment la présence d’aires protégées à l’échelle nationale influence la distribution d’autres variables également à l’échelle nationale\nDes unités administratives, comme des communes\nDes zones géographiques d’une échelle assez fine (par exemple, 1 km2), cf. par exemple Wolf et al. (Wolf et al. 2021)\nDes pixels à l’échelle la plus fine où ils sont disponible, généralement en effectuant un tirage alétaoire, cf. par exemple Devenish et al. (2022)",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Clarification sur les unités d'analyse</span>"
    ]
  },
  {
    "objectID": "07_unites_analyse.html#constitution-dun-maillage",
    "href": "07_unites_analyse.html#constitution-dun-maillage",
    "title": "7  Clarification sur les unités d’analyse",
    "section": "7.2 Constitution d’un maillage",
    "text": "7.2 Constitution d’un maillage\nOn montre ci-dessous comment cette approche fonctionne. La première étape consiste à dessiner un carré autour des aires protégées malgaches, puis à subdiviser ce grand carré en un damier de formes hexagonales. Enfin, on ne garde que les hexagones qui se trouvent dans les frontières terrestres de Madagascar.\n\n\nCode\nlibrary(tidyverse)\nlibrary(tmap)\nlibrary(sf)\nlibrary(mapme.biodiversity)\nlibrary(geodata)\nlibrary(terra)\nlibrary(future)\nlibrary(tictoc)\nlibrary(progressr)\n\ncontour_mada &lt;- gadm(country = \"Madagascar\", resolution = 1, level = 0,\n                     path = \"data\") %&gt;%\n  st_as_sf() %&gt;%\n  st_transform(\"EPSG:29739\") # On utilise la projecton officielle pour Mada\n  \n  # Création d'un maillage du territoire émergé --------------------------------\n  \n  # On crée un cadre autour des frontières nationales\ncadre_autour_mada = st_as_sf(st_as_sfc(st_bbox(contour_mada))) %&gt;%\n  st_make_valid()\n\n# Surface des hexagones en km2\ntaille_hex &lt;- 5\n\n# Cellules de 5km de rayon\nsurface_cellule &lt;- taille_hex * (1e+6)\ntaille_cellule &lt;- 2 * sqrt(surface_cellule / ((3 * sqrt(3) / 2))) * sqrt(3) / 2\ngrille_mada &lt;- st_make_grid(x = cadre_autour_mada,\n                            cellsize = taille_cellule,\n                            square = FALSE) \n# On découpe la grille pour ne garder que les terres émergées\ncellules_emergees &lt;- contour_mada %&gt;%\n  st_intersects(grille_mada) %&gt;%\n  unlist()\ngrille_mada &lt;- grille_mada[sort(cellules_emergees)] %&gt;%\n  st_sf()\n\n\nLe maillage produit est trop fin pour être visible à l’échelle du pays, mais on peut l’observer en zoomant sur une zone spécifique.\n\n\nCode\n## Carte de droite : zoom sur une zone spécifique-----------------------------\n# On crée une boîte de 100km autour de Maroantsetra\nzoom_boite &lt;- st_point(c(49.74229,-15.43487)) %&gt;% # Coordonnées de Maroantsetra\n  st_sfc(crs = \"EPSG:4326\") %&gt;% # On précise que c'est du GPS initalement\n  st_transform(crs = \"EPSG:29739\") %&gt;% # On passe en projeté\n  st_buffer(dist = 50000) %&gt;% # On crée un cercle de 50km de rayon\n  st_make_grid(n = 1) \n\n# On filtre les alvéoles pour ne garder que celles qui sont dans le zoom\ngrille_zoom &lt;- st_intersection(grille_mada, zoom_boite)\n\ntmap_mode(\"view\")\n# On génère la carte de droite\ntm_shape(grille_zoom) + \n  tm_borders() +\n  tm_basemap(\"OpenStreetMap\")",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Clarification sur les unités d'analyse</span>"
    ]
  },
  {
    "objectID": "07_unites_analyse.html#récupération-des-données-pour-le-maillage",
    "href": "07_unites_analyse.html#récupération-des-données-pour-le-maillage",
    "title": "7  Clarification sur les unités d’analyse",
    "section": "7.3 Récupération des données pour le maillage",
    "text": "7.3 Récupération des données pour le maillage\nOn va ensuite utiliser le package mapme.biodiversity pour calculer, pour chaque hexagones, une série d’indicateurs : temps de parcours jusqu’à la ville (définie comme toute localité de 5000 habitants) la plus proche en 2015, teneur du sol en argile et couvert forestier par année).\n\n\nCode\nif (file.exists(\"data/grille_mada_mapme.rds\")) {\n  grille_mada &lt;- read_rds(\"data/grille_mada_mapme.rds\")\n} else {\n  \n  # Traitement des données satellitaires avec {mapme.bidiversity}---------------\n  my_outdir &lt;- \"/vsis3/fbedecarrats/diffusion/mapme_impact_training/data/mapme\"\n\n  # Définir le répertoire de sortie\n  mapme_options(outdir = my_outdir)\n  \n  # Acquisition des données satellitaires requises (rasters)\n  grille_mada &lt;-  get_resources(x = grille_mada, \n                                get_nelson_et_al(ranges = \"5k_110mio\"),\n                                get_gfw_treecover(),\n                                get_gfw_lossyear(),\n                                get_worldpop(),\n                                get_nasa_srtm())\n  \n  plan(sequential)\n  # Calcul des indicateurs\n  plan(cluster, workers = 8)\n  \n  tic()\n  with_progress({\n    grille_mada &lt;- calc_indicators(x = grille_mada,\n                                   calc_slope())\n  }) # 2881.928 sec elapsed\n  toc()\n  tic()\n  with_progress({\n    grille_mada &lt;- calc_indicators(x = grille_mada,\n                                   calc_elevation())\n  })\n  toc() # 3043.628 sec elapsed\n  tic()\n  with_progress({\n    grille_mada &lt;- calc_indicators(x = grille_mada,\n                                   calc_traveltime())\n  })\n  toc() # 2092.765 sec elapsed\n  tic()\n  with_progress({\n    grille_mada &lt;- calc_indicators(x = grille_mada,\n                                   calc_population_count())\n  })\n  toc() # 2411.423 sec elapsed\n  tic()\n  with_progress({\n    grille_mada &lt;- calc_indicators(x = grille_mada,\n                                   calc_treecover_area())\n  })\n  toc() # 2851.659 sec elapsed\n  plan(sequential)\n  \n  # Sauvegarde du résultat\n  write_rds(grille_mada, \"data/grille_mada_mapme.rds\")\n}\n\n\nOn peut représenter sous forme de cartes et d’histogrammes les différentes valeurs des indicateurs générés à partir des données satellitaires.\n\n\nCode\nif (!file.exists(\"data/carte_mailles.png\")) {\n  grille_mada_summary &lt;- grille_mada %&gt;%\n    portfolio_long() %&gt;%\n    filter(!(variable == \"treecover\" & year(datetime) %in% 2001:2022)) %&gt;%\n    mutate(datetime = year(datetime)) %&gt;%\n    pivot_wider(names_from = c(indicator, datetime, variable, unit), values_from = value)\n\n  grille_mada_summary &lt;- grille_mada_summary   %&gt;%\n    mutate(couv_foret_2000 = `treecover_area_2000_treecover_ha` / 5,\n           pop_km2 = population_count_2000_population_sum_count / 5,\n           altitude = `elevation_2000_elevation_mean_m`,\n           pente = `slope_2000_slope_mean_degrees`,\n           dist_ville = `traveltime_2015_5k_110mio_traveltime_mean_minutes`,\n           taux_deforestation_2000_2023 = \n             -((`treecover_area_2023_treecover_ha` - \n                `treecover_area_2000_treecover_ha`)/`treecover_area_2000_treecover_ha`) * 100) \n  \n  \n  tmap_mode(\"plot\")\n  carte_acces &lt;- tm_shape(grille_mada_summary) +\n    tm_fill(\"dist_ville\",\n            title = \"Distance ville (&gt;5K hab)\",\n            palette = \"Oranges\",\n            style = \"fisher\",\n            n = 8,\n            legend.hist = TRUE) +\n    tm_layout(legend.outside = TRUE,\n              legend.hist.width = 1,\n              legend.hist.height = 1)\n  \n  carte_pop &lt;- tm_shape(grille_mada_summary) +\n    tm_fill(\"pop_km2\",\n            title = \"Population par km2\",\n            palette = \"YlOrBr\",\n            n = 8,\n            legend.hist = TRUE) +\n    tm_layout(legend.outside = TRUE,\n              legend.hist.width = 1,\n              legend.hist.height = 1)\n  \n  carte_pente &lt;- tm_shape(grille_mada_summary) +\n    tm_fill(\"pente\",\n            title = c(\"Pente\"),\n            palette = \"Blues\",\n            n = 8,\n            legend.hist = TRUE) +\n    tm_layout(legend.outside = TRUE,\n              legend.hist.width = 1,\n              legend.hist.height = 1)\n  \n  carte_alt &lt;- tm_shape(grille_mada_summary) +\n    tm_fill(\"altitude\",\n            title = \"Altitude\",\n            palette = \"Purples\",\n            n = 8,\n            legend.hist = TRUE) +\n    tm_layout(legend.outside = TRUE,\n              legend.hist.width = 1,\n              legend.hist.height = 1)\n  \n  carte_cover &lt;- graph_alt &lt;- tm_shape(grille_mada_summary) +\n    tm_fill(\"couv_foret_2000\",\n            title = \"Couvert arboré en 2000\",\n            palette = \"Greens\",\n            n = 8,\n            legend.hist = TRUE) +\n    tm_layout(legend.outside = TRUE,\n              legend.hist.width = 1,\n              legend.hist.height = 1)\n  \n  carte_loss &lt;- graph_alt &lt;- tm_shape(grille_mada_summary) +\n    tm_fill(\"taux_deforestation_2000_2023\",\n            title = \"Perte couvert (2000-2023)\",\n            palette = \"Reds\",\n            n = 8,\n            legend.hist = TRUE) +\n    tm_layout(legend.outside = TRUE,\n              legend.hist.width = 1,\n              legend.hist.height = 1)\n  \n  carte_mailles &lt;- tmap_arrange(carte_acces, carte_pop, \n                                carte_alt, carte_pente, \n                                carte_cover, carte_loss,\n                                ncol = 2, nrow = 3)\n  \n  tmap_save(carte_mailles, \"data/carte_mailles.png\")\n}\n\n\n Les cartes et histogrammes ci-dessus illustrent la distribution des variables spatiales calculées par hexagones.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Clarification sur les unités d'analyse</span>"
    ]
  },
  {
    "objectID": "07_unites_analyse.html#croisement-des-données-daires-protégées-et-satellitaires",
    "href": "07_unites_analyse.html#croisement-des-données-daires-protégées-et-satellitaires",
    "title": "7  Clarification sur les unités d’analyse",
    "section": "7.4 Croisement des données d’aires protégées et satellitaires",
    "text": "7.4 Croisement des données d’aires protégées et satellitaires\nOn peut maintenant associer les données d’aires protégées aux hexagones afin de les croiser avec les indicateurs issus des données satellitaires déjà calculés pour ces hexagones.\n\n\nCode\nif (file.exists(\"data/grille_mada_summary_AP.rds\")) {\n  grille_mada_AP &lt;- read_rds(\"data/grille_mada_summary_AP.rds\")\n} else {\n  # Load the protected areas data\n  AP_Vahatra &lt;- st_read(\"data/AP_Vahatra.geojson\", quiet = TRUE)\n  \n  # Prépare les attributs liés aux données d'AP\n  AP_info &lt;- AP_Vahatra %&gt;%\n    st_drop_geometry() %&gt;%\n    select(nom, an_creation, cat_iucn, gestionnaire = gest_2)\n  \n  # Une fonction qui extrait le premier élément ou retourne NA\n  get_first_or_na &lt;- function(indices, names_vector) {\n    if (length(indices) == 0) {\n      return(NA_character_)\n    }\n    names_vector[indices[1]]\n  }\n  \n  # On assigne le statut d'AP aux hexagones\n  grille_mada_summary_AP &lt;- grille_mada_summary %&gt;%\n    mutate(\n      AP_touche = map_chr(st_intersects(., AP_Vahatra), get_first_or_na, AP_info$nom),\n      AP_inclus = map_chr(st_within(., AP_Vahatra), get_first_or_na, AP_info$nom),\n      position_ap = case_when(\n        is.na(AP_touche) ~ \"Extérieur\",\n        !is.na(AP_inclus) ~ \"Intérieur\",\n        TRUE ~ \"Frontière\"),\n      ref_AP = if_else(position_ap == \"Intérieur\", AP_inclus, AP_touche)) %&gt;%\n    left_join(AP_info, by = c(\"ref_AP\" = \"nom\")) %&gt;%\n    st_sf()\n  \n  # On sauve le résultat pour s'en servir plus tard (matching)\n  write_rds(grille_mada_summary_AP, \"data/grille_mada_summary_AP.rds\")\n}\n\ntmap_mode(\"plot\")\n# Plot the classified map\ntm_shape(grille_mada_AP) +\n  tm_fill(\"position_ap\", title = \"par rapport aux aires protégées\") +\n  tm_layout(\n    main.title = \"Localisation des hexagones\",\n    main.title.position = c(\"center\", \"top\"),\n    main.title.size = 1,\n    legend.position = c(\"left\", \"top\"),\n    legend.outside = FALSE)\n\n\n\n\n\n\n\n\n\n\n\n\n\nDevenish, Katie, Sébastien Desbureaux, Simon Willcock, and Julia P. G. Jones. 2022. “On Track to Achieve No Net Loss of Forest at Madagascar’s Biggest Mine.” Nature Sustainability 5 (6): 498–508. https://doi.org/10.1038/s41893-022-00850-7.\n\n\nWolf, Christopher, Taal Levi, William J. Ripple, Diego A. Zárrate-Charry, and Matthew G. Betts. 2021. “A Forest Loss Report Card for the World’s Protected Areas.” Nature Ecology & Evolution 5 (4): 520–29. https://doi.org/10.1038/s41559-021-01389-0.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Clarification sur les unités d'analyse</span>"
    ]
  },
  {
    "objectID": "08_appariement.html#application-sur-les-données-en-mailles",
    "href": "08_appariement.html#application-sur-les-données-en-mailles",
    "title": "8  Méthodes d’appariement",
    "section": "8.6 Application sur les données en mailles",
    "text": "8.6 Application sur les données en mailles\nL’exercice ci-dessous consiste à réaliser un appariement sur des données d’une taille relativement grande. Cet exercice comporte des limites, car on dispose d’un nombre limité d’observations à comparer.\nUne approche plus appropriée consiste à utiliser le maillage du territoire effectué dans la section Chapter 7 pour comparer des parcelles d’aires passées sous protection pendant la période d’étude (2000-2023) à des zones d’ayant jamais été protégées.\nLes données ne peuvent pas contenir de données manquantes sur les variables d’appariement, donc on les écarte.\n\n\nCode\nlibrary(tidyverse)\nlibrary(mapme.biodiversity)\nlibrary(MatchIt)\nlibrary(stargazer)\nlibrary(sf)\nlibrary(cobalt)\nlibrary(tmap)\nlibrary(htmltools) # Pour avoir de plus jolies tables\nlibrary(geodata) # Pour les frontières de Madagascar\n\n# Taille des titres des cartes\ntaille_titres_cartes = 1\n\ngrille_mada_summary_AP &lt;- read_rds(\"data/grille_mada_summary_AP.rds\")\n\n# On référence le nom des variables qui vont servir à l'analyse\nvariables_analyse &lt;- c(\"assetid\",\n                       \"traitement\",\n                       \"couv_foret_2000\",\n                       \"pop_km2\",\n                       \"altitude\",\n                       \"pente\",\n                       \"dist_ville\",\n                       \"taux_deforestation_2000_2023\")\n\n# On renomme le ficher 'df' (dataframe) : plus concis dans les commandes ensuite\ndf &lt;- grille_mada_summary_AP %&gt;%\n  # On supprime toutes les lignes pour lesquelles au moins 1 valeur variable \n  # est manquante parmi les variables d'analyse\n  mutate(traitement = position_ap == \"Intérieur\") %&gt;% \n  drop_na(any_of(variables_analyse))\n\n\nOn analyse maintenant le score de propension.\n\n\nCode\n# Get propensity scores\nglm_out &lt;- glm(traitement ~ couv_foret_2000 + \n                           pop_km2 + \n                           altitude + \n                           pente + \n                           dist_ville,  \n               family = binomial(link = \"probit\"),\n               data = df)\n\ncellmatch_out1 &lt;- stargazer(glm_out,\n                            summary = TRUE,\n                            type = \"html\",\n                            title = \"Score de propension\")\n\n\n\n\n\n\nScore de propension\n\n\n\n\n\n\nDependent variable:\n\n\n\n\n\n\n\ntraitement\n\n\n\n\n\ncouv_foret_2000\n0.013***\n\n\n\n(0.0002)\n\n\n\n\n\n\npop_km2\n-0.021***\n\n\n\n(0.001)\n\n\n\n\n\n\naltitude\n0.001***\n\n\n\n(0.00002)\n\n\n\n\n\n\npente\n-0.041***\n\n\n\n(0.002)\n\n\n\n\n\n\ndist_ville\n0.0004***\n\n\n\n(0.00004)\n\n\n\n\n\n\nConstant\n-1.574***\n\n\n\n(0.017)\n\n\n\n\n\n\n\n\n\nObservations\n58,514\n\n\nLog Likelihood\n-18,220.730\n\n\nAkaike Inf. Crit.\n36,453.460\n\n\n\n\n\nNote:\n*p&lt;0.1; **p&lt;0.05; ***p&lt;0.01\n\n\n\n\n\n\n\nExercice : interpréter le résultat du score de propension.\n\n\n\nCode\nm_out &lt;- matchit(traitement ~ couv_foret_2000 + \n                           pop_km2 + \n                           altitude + \n                           pente + \n                           dist_ville,\n                 data = df,\n                 method = \"nearest\",\n                 replace = TRUE,\n                 distance = \"glm\", \n                 discard = \"both\", # common support: drop units from both groups \n                 link = \"probit\")\n\nprint(m_out)\n\n\nA matchit object\n - method: 1:1 nearest neighbor matching with replacement\n - distance: Propensity score [common support]\n             - estimated with probit regression\n - common support: units from both groups dropped\n - number of obs.: 58514 (original), 12670 (matched)\n - target estimand: ATT\n - covariates: couv_foret_2000, pop_km2, altitude, pente, dist_ville\n\n\nCode\n# print(summary(m_out, un = FALSE))\nbal_table &lt;- bal.tab(m_out, un = TRUE)\nprint(bal_table)\n\n\nBalance Measures\n                    Type Diff.Un Diff.Adj\ndistance        Distance  0.9619   0.0000\ncouv_foret_2000  Contin.  0.7786  -0.0001\npop_km2          Contin. -1.2823  -0.0729\naltitude         Contin.  0.3385  -0.0240\npente            Contin.  0.1808   0.0344\ndist_ville       Contin.  0.4796  -0.0240\n\nSample sizes\n                      Control Treated\nAll                  51300.      7214\nMatched (ESS)         3928.27    7199\nMatched (Unweighted)  5471.      7199\nUnmatched            45294.         0\nDiscarded              535.        15\n\n\nCode\nm_data &lt;- match.data(m_out) %&gt;%\n  st_sf()\n\ncontour_mada &lt;- gadm(\"Madagascar\", level = 0, path = \"data\") %&gt;% st_as_sf()\n# On visualise les données appareillées\ntm_shape(contour_mada) +\n  tm_borders() +\n  tm_shape(m_data) +\n  tm_fill(col = \"traitement\", palette = \"Set1\", title = \"Groupes d'appariement\",\n          labels = c(\"Contrôle\", \"Traitement\")) +\n  tm_layout(legend.outside = TRUE,\n            main.title = \"Localisation des groupes de traitement et de contrôle\",\n            main.title.position = c(\"center\", \"top\"),\n            main.title.size = 1)\n\n\n\n\n\n\n\n\n\n\nExercice: Réaliser des tests d’équilibre\n\nOn réalise la régression.\n\n\nCode\nmodele &lt;- lm(formula = taux_deforestation_2000_2023 ~\n               traitement +\n               couv_foret_2000 + \n               pop_km2 + \n               altitude + \n               pente + \n               dist_ville,\n             data = m_data,\n             weights = weights)\ncellmatch_out2 &lt;- stargazer(modele, type = \"html\") \n\n\n\n\n\n\n\n\n\n\n\n\nDependent variable:\n\n\n\n\n\n\n\ntaux_deforestation_2000_2023\n\n\n\n\n\ntraitement\n-12.880***\n\n\n\n(0.403)",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Méthodes d'appariement</span>"
    ]
  },
  {
    "objectID": "09_double_difference.html",
    "href": "09_double_difference.html",
    "title": "9  Double différence",
    "section": "",
    "text": "9.1 Méthode des doubles différences\nCliquer ici pour télécharger la présentation.\nPour cette analyse, nous allons appliquer la méthode des doubles différences pour estimer l’impact des aires protégées sur la déforestation à Madagascar entre 2000 et 2021. Cette méthode est particulièrement utile lorsque l’intervention (la création des aires protégées) a lieu à des dates différentes pour chaque unité d’observation, ce que l’on appelle un échelonnement (staggered diff-in-diff). La méthode proposée par Callaway et Sant’Anna (2021b) permet de gérer cette situation en utilisant une approche qui tient compte de ces dates de mise en œuvre différentes. Le package {did} (Callaway and Sant’Anna 2021a) en R permet d’appliquer cette méthode facilement.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Double différence</span>"
    ]
  },
  {
    "objectID": "09_double_difference.html#application-aux-mailles-de-territoire",
    "href": "09_double_difference.html#application-aux-mailles-de-territoire",
    "title": "9  Double différence",
    "section": "9.2 Application aux mailles de territoire",
    "text": "9.2 Application aux mailles de territoire\nDans cette section, nous appliquons la méthode des doubles différences aux mailles de territoire pour évaluer l’effet des aires protégées sur la réduction de la déforestation. Nous allons d’abord préparer les données afin de les rendre conformes aux exigences de la fonction att_gt() du package {did}.\nNous travaillons avec un jeu de données spatial qui représente des mailles de 1 km² chacune, et nous avons des informations sur la couverture forestière pour chaque année. Le traitement consiste à identifier les mailles qui sont “intérieures” aux aires protégées (traitées) par rapport aux autres (non traitées).\n\n\nCode\nlibrary(did) # Pour des doubles-différences échelonnées\nlibrary(tidyverse) # Pur faciliter la manipulation de données\nlibrary(lubridate) # Pour modifier les dates\nlibrary(gt) # Pour de jolis tableaux\nlibrary(mapme.biodiversity) # Pour réutiliser des fonctions portfolio_long\nlibrary(sf) # Pour des opérations spatiales sur vecteurs\n\n# On charge les données par mailles créées précédemment\ngrille_matched &lt;- read_rds(\"data/grille_matched.rds\")\n# Dans la version ci-dessus, on n'a gardé que les données de déforestation\n# par année. On va récupérer dans la version précédente, le calcul qu'on avait pour toutes les années\ngrille_mada_mapme &lt;- read_rds(\"data/grille_mada_mapme.rds\")\n# On isole l'identifiant de la cellule et les indicateurs de perte de couvert forestier\ntreecover_data &lt;- grille_mada_mapme %&gt;%\n  st_drop_geometry() %&gt;%\n  select(assetid, treecover_area)\n# On incorpore les données détaillées de couvert forestier dans les données matchées\ngrille_matched &lt;- grille_matched %&gt;%\n  left_join(treecover_data, by = \"assetid\")\n\n\nIci, nous avons associé les données sur la perte de couverture forestière à chaque maille correspondant aux aires protégées et aux zones non protégées.\nEnsuite, nous transformons les données en format long pour pouvoir suivre l’évolution de la couverture forestière au fil du temps. Cela permet de calculer le taux de déforestation annuel comme un pourcentage du couvert forestier initial pour chaque maille.\n\n\nCode\n# On va utiliser matchit pour \"déplier\" en mode long l'évolution du couvert forestier\n# On indique qu'il s'agit d'un objet de type mapme.biodiversity pour pouvoir \n# utiliser la fonction portfolio_long\nclass(grille_matched) &lt;- class(grille_mada_mapme) \n# On passe maintenant en format long\ngrille_matched &lt;- grille_matched %&gt;%\n  portfolio_long() %&gt;%\n  rename(treecover = value) %&gt;%\n  mutate(years = year(datetime)) %&gt;%\n  arrange(assetid, years) %&gt;% # On remet bien dans l'ordre pour que les années se suivent\n  # On calcule le taux de déforestation en %\n  mutate(tx_defor = ifelse(assetid!= lag(assetid), NA, \n                           -((treecover - lag(treecover)) / \n                               lag(treecover))*100))\n\n\n\nExercice : - pour explorer le jeu de données grilles_matched, groupez les données par statut de traitement traitement et année de création an_creation. Que remarquez-vous ?\n\n\n9.2.1 Estimation des effets moyens du traitement\nNous utilisons la fonction att_gt() pour estimer l’effet moyen du traitement (ATT) sur le taux de déforestation au fil du temps. Les poids provenant du processus de matching sont utilisés pour ajuster les estimations.\nLa fonction ggdid() permet de visualiser les résultats obtenus. Les graphiques suivants montrent l’évolution de l’ATT au fil du temps, ce qui nous permet d’observer l’impact des aires protégées sur la déforestation. Attention : il s’agit ici d’une première estimation à des fins didactiques, sans variables de contrôle.\n\n\nCode\n# Les mailles en dehors des aires protégées sont considérées comme jamais traitées\ngrille_matched &lt;- grille_matched %&gt;%\n  mutate(time_treated = ifelse(position_ap == \"Intérieur\", an_creation, 0))\n\n# Calculer le DID en utilisant la fonction `att_gt`\ndid_result &lt;- att_gt(yname = \"tx_defor\", # variable de résultat\n                     tname = \"years\", # Variable de temps\n                     idname = \"assetid\", # ID des unités\n                     gname = \"time_treated\", # Temps de traitement \n                     weightsname = \"weights\", # Poids issus du matching\n                     data = grille_matched,\n                     panel = TRUE) # panel veut dire qu'on suit les mêmes unités\n\n# Plot the results to visualize the ATT over time\nggdid(did_result)\n\n\n\n\n\n\n\n\n\n\nExercice : Analysez et commentez ce résultat.\n\n\n\n9.2.2 Agrégation des résultats\nNous pouvons également agréger les résultats pour obtenir une estimation globale des effets moyens du traitement par “cohorte” d’année de création des aires protégées.\n\n\nCode\n# Aggregate the ATT results\nagg_att_mailles &lt;- aggte(did_result, type = \"group\")\n\n# Display the aggregated results\nsummary(agg_att_mailles)\n\n\n\nCall:\naggte(MP = did_result, type = \"group\")\n\nReference: Callaway, Brantly and Pedro H.C. Sant'Anna.  \"Difference-in-Differences with Multiple Time Periods.\" Journal of Econometrics, Vol. 225, No. 2, pp. 200-230, 2021. &lt;https://doi.org/10.1016/j.jeconom.2020.12.001&gt;, &lt;https://arxiv.org/abs/1803.09015&gt; \n\n\nOverall summary of ATT's based on group/cohort aggregation:  \n     ATT    Std. Error     [ 95%  Conf. Int.]  \n -0.3733        0.0833    -0.5366     -0.2101 *\n\n\nGroup Effects:\n Group Estimate Std. Error [95% Simult.  Conf. Band]  \n  2002  -0.3285     0.2338       -0.9331      0.2761  \n  2004  -1.4903     0.0359       -1.5830     -1.3975 *\n  2007  -1.8861     0.0778       -",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Double différence</span>"
    ]
  }
]